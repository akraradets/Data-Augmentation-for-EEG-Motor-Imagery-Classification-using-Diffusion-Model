{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851d3258-8cf6-45d4-8f14-0132010a75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c741fe2-c493-4c5c-bc93-d1625e72b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c54d231-fe5f-4735-aebf-6ef5a4d8e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw done\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 sec)\n",
      "\n",
      "Filtering raw data in 6 contiguous segments\n",
      "Setting up band-pass filter from 8 - 14 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 14.00 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz (-6 dB cutoff frequency: 15.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 801 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[   672,      0,      1],\n",
       "        [  2000,      0,      0],\n",
       "        [  3328,      0,      0],\n",
       "        [  4656,      0,      1],\n",
       "        [  5984,      0,      1],\n",
       "        [  7312,      0,      0],\n",
       "        [  8640,      0,      0],\n",
       "        [  9968,      0,      1],\n",
       "        [ 11296,      0,      0],\n",
       "        [ 12624,      0,      1],\n",
       "        [ 13952,      0,      1],\n",
       "        [ 15280,      0,      0],\n",
       "        [ 16608,      0,      0],\n",
       "        [ 17936,      0,      1],\n",
       "        [ 19264,      0,      0],\n",
       "        [ 20672,      0,      1],\n",
       "        [ 22000,      0,      0],\n",
       "        [ 23328,      0,      0],\n",
       "        [ 24656,      0,      1],\n",
       "        [ 25984,      0,      1],\n",
       "        [ 27312,      0,      0],\n",
       "        [ 28640,      0,      1],\n",
       "        [ 29968,      0,      0],\n",
       "        [ 31296,      0,      1],\n",
       "        [ 32624,      0,      0],\n",
       "        [ 33952,      0,      0],\n",
       "        [ 35280,      0,      1],\n",
       "        [ 36608,      0,      0],\n",
       "        [ 37936,      0,      1],\n",
       "        [ 39264,      0,      0],\n",
       "        [ 40672,      0,      0],\n",
       "        [ 42000,      0,      1],\n",
       "        [ 43328,      0,      0],\n",
       "        [ 44656,      0,      1],\n",
       "        [ 45984,      0,      0],\n",
       "        [ 47312,      0,      1],\n",
       "        [ 48640,      0,      1],\n",
       "        [ 49968,      0,      0],\n",
       "        [ 51296,      0,      0],\n",
       "        [ 52624,      0,      1],\n",
       "        [ 53952,      0,      1],\n",
       "        [ 55280,      0,      0],\n",
       "        [ 56608,      0,      1],\n",
       "        [ 57936,      0,      0],\n",
       "        [ 59264,      0,      0],\n",
       "        [ 60672,      0,      0],\n",
       "        [ 62000,      0,      1],\n",
       "        [ 63328,      0,      0],\n",
       "        [ 64656,      0,      1],\n",
       "        [ 65984,      0,      0],\n",
       "        [ 67312,      0,      1],\n",
       "        [ 68640,      0,      0],\n",
       "        [ 69968,      0,      1],\n",
       "        [ 71296,      0,      1],\n",
       "        [ 72624,      0,      0],\n",
       "        [ 73952,      0,      0],\n",
       "        [ 75280,      0,      1],\n",
       "        [ 76608,      0,      1],\n",
       "        [ 77936,      0,      0],\n",
       "        [ 79264,      0,      0],\n",
       "        [ 80672,      0,      0],\n",
       "        [ 82000,      0,      1],\n",
       "        [ 83328,      0,      1],\n",
       "        [ 84656,      0,      0],\n",
       "        [ 85984,      0,      1],\n",
       "        [ 87312,      0,      0],\n",
       "        [ 88640,      0,      0],\n",
       "        [ 89968,      0,      1],\n",
       "        [ 91296,      0,      1],\n",
       "        [ 92624,      0,      0],\n",
       "        [ 93952,      0,      0],\n",
       "        [ 95280,      0,      1],\n",
       "        [ 96608,      0,      1],\n",
       "        [ 97936,      0,      0],\n",
       "        [ 99264,      0,      1],\n",
       "        [100672,      0,      1],\n",
       "        [102000,      0,      0],\n",
       "        [103328,      0,      1],\n",
       "        [104656,      0,      0],\n",
       "        [105984,      0,      0],\n",
       "        [107312,      0,      1],\n",
       "        [108640,      0,      1],\n",
       "        [109968,      0,      0],\n",
       "        [111296,      0,      0],\n",
       "        [112624,      0,      1],\n",
       "        [113952,      0,      1],\n",
       "        [115280,      0,      0],\n",
       "        [116608,      0,      1],\n",
       "        [117936,      0,      0],\n",
       "        [119264,      0,      1]]),\n",
       " {'T1': 0, 'T2': 1},\n",
       " <Epochs |  90 events (all good), -1 - 4 sec, baseline -1 – 0 sec, ~35.3 MB, data loaded,\n",
       "  'T1': 46\n",
       "  'T2': 44>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = 'physionet.org/files/eegmmidb/1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "#runs = [4, 8, 12]\n",
    "subjects = [1]#[i for i in range(1,40)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "print(\"Raw done\")\n",
    "# apply filter\n",
    "\n",
    "raw=raw.notch_filter([50])\n",
    "raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d908b499-5342-426b-b5cb-c4afdd4887ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 64, 801) (90,)\n",
      "(90, 2, 801)\n"
     ]
    }
   ],
   "source": [
    "# pick 7 channels.\n",
    "#X2 = X[:, :14, :]\n",
    "# = X2\n",
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "X = X[:,:,:]\n",
    "X.shape\n",
    "# pick C3 and C4 channels.\n",
    "X2 = X[:, 8:9, :] \n",
    "X3= X[:, 12:13, :]\n",
    "X = np.concatenate((X2,X3), axis=1)\n",
    "# = X4\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa4ab14-d3e8-4b87-9a1f-3fb522d64af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (63, 2, 801) (63,)\n",
      "Test size (27, 2, 801) (27,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "print('train size',X_train.shape, y_train.shape)\n",
    "print('Test size',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b137eb-dd3a-4846-bb9b-9fe0d6bfd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#batch_size = 801\n",
    "\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea375e6-69a7-4c94-b0b2-5c156434b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size = X_train.shape[2]\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "in_channels  = X.shape[1] #C3, C4\n",
    "out_channels = 64  #five is logical because we have freq= 8, 9, 10, 11, 12 that we want to capture\n",
    "out_size     = 2  #left or right\n",
    "kernel_size  = 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086871a3-b5ed-4865-bdc8-372270251077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, out_size):\n",
    "        super().__init__()\n",
    "        #using sequential helps bind multiple operations together\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #padding = (kernel_size - 1) / 2 = 2\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels*2),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(linear_shape  , out_size)\n",
    "        #self.fc = nn.Linear(80064 , 2)\n",
    "        \n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.drop_out(out)\n",
    "        #out = self.layer4(out)\n",
    "        #out = self.drop_out(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)   #can also use .view()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66c69f0-ae35-4bba-bbde-816a651a130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_2d, self).__init__()\n",
    "        \n",
    "        #using sequential helps bind multiple operations together\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #padding = (kernel_size - 1) / 2 = 2\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Linear(615168, 2)\n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = out.reshape(out.size(0), -1)   #can also use .view()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44e3f63-6eee-4c4d-a220-79e615018a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d43a9b1-3ebc-4c7d-a1e7-961ed1675656",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_eeg_data = torch.randn_like(X_train) #(batch_size, channel, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dac2ebb-7ee6-4db6-b248-6e28ef39da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        #using sequential helps bind multiple operations together\n",
    "layer1 = nn.Sequential(\n",
    "            #padding = (kernel_size - 1) / 2 = 2\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "layer2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels*2),\n",
    "            nn.ReLU()\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "layer3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712990fa-6971-467a-922b-72e08cebd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 64, 801])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer1(fake_eeg_data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c3475c-492d-47ec-890f-aad0906efd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 128, 801])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer2(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69689dd8-3276-47d1-9194-8f3bb5fcc961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 64, 801])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer3(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deb38ee8-ca25-4b41-8dcd-6b3c6ce04fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.reshape(out.size(0), -1)\n",
    "\n",
    "linear_shape = out.shape[1]\n",
    "linear_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b27f9e8-401d-4799-849b-df2d0fb793fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(linear_shape, out_size)\n",
    "out = fc(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17760388-df51-4c8c-9ecc-ec81da1946a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnutapol-1997\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nutapolt/eeg_mi/wandb/run-20230111_034506-oppdjxfb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nutapol-1997/Motor-Imagery/runs/oppdjxfb\" target=\"_blank\">physionet_CNN_1D_7ch_2class</a></strong> to <a href=\"https://wandb.ai/nutapol-1997/Motor-Imagery\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "wand = wandb.init(\n",
    "        \n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"physionet_CNN_1D_7ch_2class\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.000001,\n",
    "      \"architecture\": \"CNN2D\",\n",
    "      \"dataset\": \"physionet\",\n",
    "      \"epochs\": 100000000,\n",
    "      \"weightname\":\"physionet_CNN_1D_7ch_2class\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "        \n",
    "      }\n",
    "    )\n",
    "\n",
    "config = wand.config\n",
    "print(config.num_step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eccef9ae-6ad7-4d2e-8035-88fcb28d1ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000000, Tr Loss: 0.7397, Tr Acc: 47.6190, Val Loss: 0.6937, Val Acc: 48.1481\n",
      "Epoch 101/100000000, Tr Loss: 0.6978, Tr Acc: 58.7302, Val Loss: 0.6918, Val Acc: 51.8519\n",
      "Epoch 201/100000000, Tr Loss: 0.6312, Tr Acc: 63.4921, Val Loss: 0.6902, Val Acc: 51.8519\n",
      "Epoch 301/100000000, Tr Loss: 0.5718, Tr Acc: 73.0159, Val Loss: 0.6904, Val Acc: 48.1481\n",
      "Epoch 401/100000000, Tr Loss: 0.5506, Tr Acc: 80.9524, Val Loss: 0.6920, Val Acc: 55.5556\n",
      "Epoch 501/100000000, Tr Loss: 0.5066, Tr Acc: 80.9524, Val Loss: 0.6989, Val Acc: 55.5556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 7\u001b[0m train_loss,valid_loss,train_accuracy,valid_accuracy \u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwand\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m wandb\u001b[38;5;241m.\u001b[39malert(\n\u001b[1;32m     19\u001b[0m             title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinish\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m             text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinishing training\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m         )\n",
      "File \u001b[0;32m~/eeg_mi/common.py:86\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, gpu_num, train_loader, test_loader, optimizer, criterion, wand, vail_loader, cross)\u001b[0m\n\u001b[1;32m     83\u001b[0m     classes \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mcuda(gpu_num)\n\u001b[1;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 86\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, classes)\n\u001b[1;32m     89\u001b[0m iter_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [8], line 36\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_out(out)\n\u001b[0;32m---> 36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#out = self.drop_out(out)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#out = self.layer4(out)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#out = self.drop_out(out)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mreshape(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)   \u001b[38;5;66;03m#can also use .view()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:296\u001b[0m, in \u001b[0;36mBatchNorm1d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBatchNorm1d\u001b[39;00m(_BatchNorm):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies Batch Normalization over a 2D or 3D input as described in the paper\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    `Batch Normalization: Accelerating Deep Network Training by Reducing\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    Internal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m        >>> output = m(input)\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 2D or 3D input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim())\n\u001b[1;32m    300\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from common import train\n",
    "net = ConvNet(in_channels, out_channels, kernel_size, out_size).cuda(0)\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    gpu_num = 0,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    wand = wand\n",
    "         )\n",
    "\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463cc08-42bf-44bf-bb60-f8f91c6ca4d9",
   "metadata": {},
   "source": [
    "### validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bed1c2d-2be1-48fd-976e-2da1001f0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "del net\n",
    "net = ConvNet().cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fdb330a-630d-44a7-9b63-a9c8e63e7d17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw done\n",
      ">>> Apply filter.\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 529 samples (3.306 sec)\n",
      "\n",
      "Filter done\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 641 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  672,     0,     0],\n",
       "        [ 2000,     0,     1],\n",
       "        [ 3328,     0,     1],\n",
       "        [ 4656,     0,     0],\n",
       "        [ 5984,     0,     0],\n",
       "        [ 7312,     0,     1],\n",
       "        [ 8640,     0,     1],\n",
       "        [ 9968,     0,     0],\n",
       "        [11296,     0,     1],\n",
       "        [12624,     0,     0],\n",
       "        [13952,     0,     1],\n",
       "        [15280,     0,     0],\n",
       "        [16608,     0,     1],\n",
       "        [17936,     0,     0],\n",
       "        [19264,     0,     0],\n",
       "        [20672,     0,     0],\n",
       "        [22000,     0,     1],\n",
       "        [23328,     0,     0],\n",
       "        [24656,     0,     1],\n",
       "        [25984,     0,     1],\n",
       "        [27312,     0,     0],\n",
       "        [28640,     0,     0],\n",
       "        [29968,     0,     1],\n",
       "        [31296,     0,     1],\n",
       "        [32624,     0,     0],\n",
       "        [33952,     0,     1],\n",
       "        [35280,     0,     0],\n",
       "        [36608,     0,     1],\n",
       "        [37936,     0,     0],\n",
       "        [39264,     0,     1],\n",
       "        [40672,     0,     0],\n",
       "        [42000,     0,     1],\n",
       "        [43328,     0,     1],\n",
       "        [44656,     0,     0],\n",
       "        [45984,     0,     1],\n",
       "        [47312,     0,     0],\n",
       "        [48640,     0,     0],\n",
       "        [49968,     0,     1],\n",
       "        [51296,     0,     1],\n",
       "        [52624,     0,     0],\n",
       "        [53952,     0,     0],\n",
       "        [55280,     0,     1],\n",
       "        [56608,     0,     0],\n",
       "        [57936,     0,     1],\n",
       "        [59264,     0,     1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = 'physionet.org/files/eegmmidb/1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "#runs = [3, 4, 7, 8, 11, 12]\n",
    "runs = [4, 8, 12]\n",
    "subjects = [i for i in range(83,84)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "print(\"Raw done\")\n",
    "# apply filter\n",
    "freq = (1., 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.data_to_raw()\n",
    "print(\"Filter done\")\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d776b41-bffa-4706-8e0b-b401ae6e9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2, 641)\n"
     ]
    }
   ],
   "source": [
    "# pick 7 channels.\n",
    "#X2 = X[:, :14, :]\n",
    "# = X2\n",
    "\n",
    "# pick C3 and C4 channels.\n",
    "\n",
    "X_val, y_val = eeg.get_X_y()\n",
    "\n",
    "X2 = X_val[:, 1:2, :] \n",
    "X3= X_val[:, 5:6, :]\n",
    "X_val = np.concatenate((X2,X3), axis=1)\n",
    "# = X4\n",
    "#X_val = X_val[:, :,np.newaxis,:]\n",
    "print(X_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e591afc7-bae9-44e4-95a9-7410b980da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = create_dataloader(X_val, y_val, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca5717-2aa6-49e3-8cd3-41a4a7cf9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e75f0fb0-2262-4a55-828d-dd30f3179a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Acc: 48.8889\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 1\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "old_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    net.eval()\n",
    "    for i, (items, classes) in enumerate(test_loader):\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        \n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(1)\n",
    "            classes = classes.cuda(1)\n",
    "        \n",
    "        outputs = net(items)\n",
    "        loss += criterion(outputs, classes).item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data).sum()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    valid_loss.append(loss/iterations)\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) * 100.0)\n",
    "print (' Val Acc: %.4f'\n",
    "                   %(valid_accuracy[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b544cb1-a832-460c-a623-f682258d9128",
   "metadata": {},
   "source": [
    "### Freeze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faa605c3-b85d-4c73-98ff-f2a1194b3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del net\n",
    "net = ConvNet().cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095d271e-be36-40ab-8c37-1ba617aff35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model_2class_2ch_CNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37cb4f-0483-4927-ab86-a7656cc580ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f879a0a6-89f1-4c17-8b85-4c301377e303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer1.1.running_mean', 'layer1.1.running_var', 'layer1.1.num_batches_tracked', 'layer2.0.weight', 'layer2.0.bias', 'layer2.1.weight', 'layer2.1.bias', 'layer2.1.running_mean', 'layer2.1.running_var', 'layer2.1.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms = net.state_dict()\n",
    "parms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45dc7b5e-38bd-4be1-aa32-a11f5e8ef3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad and 'layer1' in name:\n",
    "        param.requires_grad = False\n",
    "    if param.requires_grad and 'layer2' in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6322a06c-e29f-497f-9e3d-7c08b0e23f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw done\n",
      ">>> Apply filter.\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 529 samples (3.306 sec)\n",
      "\n",
      "Filter done\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 641 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  672,     0,     0],\n",
       "        [ 2000,     0,     1],\n",
       "        [ 3328,     0,     1],\n",
       "        [ 4656,     0,     0],\n",
       "        [ 5984,     0,     0],\n",
       "        [ 7312,     0,     1],\n",
       "        [ 8640,     0,     1],\n",
       "        [ 9968,     0,     0],\n",
       "        [11296,     0,     1],\n",
       "        [12624,     0,     0],\n",
       "        [13952,     0,     1],\n",
       "        [15280,     0,     0],\n",
       "        [16608,     0,     1],\n",
       "        [17936,     0,     0],\n",
       "        [19264,     0,     0],\n",
       "        [20672,     0,     0],\n",
       "        [22000,     0,     1],\n",
       "        [23328,     0,     0],\n",
       "        [24656,     0,     1],\n",
       "        [25984,     0,     1],\n",
       "        [27312,     0,     0],\n",
       "        [28640,     0,     0],\n",
       "        [29968,     0,     1],\n",
       "        [31296,     0,     1],\n",
       "        [32624,     0,     0],\n",
       "        [33952,     0,     1],\n",
       "        [35280,     0,     0],\n",
       "        [36608,     0,     1],\n",
       "        [37936,     0,     0],\n",
       "        [39264,     0,     1],\n",
       "        [40672,     0,     0],\n",
       "        [42000,     0,     1],\n",
       "        [43328,     0,     1],\n",
       "        [44656,     0,     0],\n",
       "        [45984,     0,     1],\n",
       "        [47312,     0,     0],\n",
       "        [48640,     0,     0],\n",
       "        [49968,     0,     1],\n",
       "        [51296,     0,     1],\n",
       "        [52624,     0,     0],\n",
       "        [53952,     0,     0],\n",
       "        [55280,     0,     1],\n",
       "        [56608,     0,     0],\n",
       "        [57936,     0,     1],\n",
       "        [59264,     0,     1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = 'physionet.org/files/eegmmidb/1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "#runs = [3, 4, 7, 8, 11, 12]\n",
    "runs = [4, 8, 12]\n",
    "subjects = [i for i in range(83,84)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "print(\"Raw done\")\n",
    "# apply filter\n",
    "freq = (1., 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.data_to_raw()\n",
    "print(\"Filter done\")\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "213faa07-a62b-4cd9-b769-79c873f76637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64, 641) (45,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 64, 641)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X = X[:,:,:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c393ed-c245-4609-ab84-3d4a485fb397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2, 641)\n"
     ]
    }
   ],
   "source": [
    "# pick 7 channels.\n",
    "#X2 = X[:, :14, :]\n",
    "# = X2\n",
    "\n",
    "# pick C3 and C4 channels.\n",
    "X2 = X[:, 1:2, :] \n",
    "X3= X[:, 5:6, :]\n",
    "X = np.concatenate((X2,X3), axis=1)\n",
    "# = X4\n",
    "#X = X[:, :,np.newaxis,:]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f888af08-13a2-46d4-a75d-9efd94b6dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 2, 641) (31,)\n",
      "(14, 2, 641) (14,)\n",
      "(9, 2, 641) (9,)\n",
      "(5, 2, 641) (5,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "X_test, X_vail, y_test, y_vail = train_test_split(X_test, y_test, test_size=0.3)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_vail.shape, y_vail.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfaba4cf-417a-4b2d-bf00-65081c4dadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0342085-ba8c-4f89-b6ed-bbab7d5dcd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=0.00001)\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.00001)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "247d40ad-e0ab-41d0-a8cc-596ddb62acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2uc5s4n8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td>▃▆▃▆▅▄▇▁▅▃▅▅▆▅▇▃▄▇▆▆▂▆▇▆▅▆▂▅▇▅▅▇▅█▃▄▇▇▅▆</td></tr><tr><td>train/train_loss</td><td>▆▅▅▃▄▄▂█▅▆▄▄▃▅▂▅▄▄▄▃▄▃▃▂▅▂▆▄▃▄▄▃▅▂▇▆▁▂▅▄</td></tr><tr><td>val/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_loss</td><td>▂▂▃▁▁▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▆▆▇▇▇▇▇▇▇██▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td>58.06451</td></tr><tr><td>train/train_loss</td><td>0.61564</td></tr><tr><td>val/val_accuracy</td><td>44.44444</td></tr><tr><td>val/val_loss</td><td>0.70689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">physionet_CNN_2ch_2class_findtune</strong>: <a href=\"https://wandb.ai/nutapol-1997/Motor-Imagery/runs/2uc5s4n8\" target=\"_blank\">https://wandb.ai/nutapol-1997/Motor-Imagery/runs/2uc5s4n8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220830_094444-2uc5s4n8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2uc5s4n8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nutapolt/eeg_mi/wandb/run-20220830_094657-wdtze9a9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nutapol-1997/Motor-Imagery/runs/wdtze9a9\" target=\"_blank\">physionet_CNN_2ch_2class_findtune</a></strong> to <a href=\"https://wandb.ai/nutapol-1997/Motor-Imagery\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "wand = wandb.init(\n",
    "        \n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"physionet_CNN_2ch_2class_findtune\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.00001,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"Nutapol T.\",\n",
    "      \"epochs\": 1000,\n",
    "      \"weightname\":\"physionet_CNN_2ch_2class_findtune\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "        \n",
    "      }\n",
    "    )\n",
    "\n",
    "config = wand.config\n",
    "print(config.num_step_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04d87cbc-d0e6-4775-b088-bbdc208d8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Tr Loss: 0.7681, Tr Acc: 51.6129, Val Loss: 0.6944, Val Acc: 44.4444\n",
      "Epoch 51/1000, Tr Loss: 0.3673, Tr Acc: 93.5484, Val Loss: 0.6978, Val Acc: 44.4444\n",
      "Epoch 101/1000, Tr Loss: 0.1894, Tr Acc: 100.0000, Val Loss: 0.6939, Val Acc: 55.5556\n",
      "Epoch 151/1000, Tr Loss: 0.1083, Tr Acc: 100.0000, Val Loss: 0.8272, Val Acc: 55.5556\n",
      "Epoch 201/1000, Tr Loss: 0.0701, Tr Acc: 100.0000, Val Loss: 0.8570, Val Acc: 66.6667\n",
      "Epoch 251/1000, Tr Loss: 0.0543, Tr Acc: 100.0000, Val Loss: 0.9011, Val Acc: 55.5556\n",
      "Epoch 301/1000, Tr Loss: 0.0489, Tr Acc: 100.0000, Val Loss: 0.9500, Val Acc: 55.5556\n",
      "Epoch 351/1000, Tr Loss: 0.0333, Tr Acc: 100.0000, Val Loss: 0.9691, Val Acc: 55.5556\n",
      "Epoch 401/1000, Tr Loss: 0.0281, Tr Acc: 100.0000, Val Loss: 0.9662, Val Acc: 66.6667\n",
      "Epoch 451/1000, Tr Loss: 0.0222, Tr Acc: 100.0000, Val Loss: 0.9656, Val Acc: 66.6667\n",
      "Epoch 501/1000, Tr Loss: 0.0200, Tr Acc: 100.0000, Val Loss: 1.0178, Val Acc: 66.6667\n",
      "Epoch 551/1000, Tr Loss: 0.0175, Tr Acc: 100.0000, Val Loss: 1.0054, Val Acc: 66.6667\n",
      "Epoch 601/1000, Tr Loss: 0.0121, Tr Acc: 100.0000, Val Loss: 1.0287, Val Acc: 66.6667\n",
      "Epoch 651/1000, Tr Loss: 0.0109, Tr Acc: 100.0000, Val Loss: 1.0626, Val Acc: 55.5556\n",
      "Epoch 701/1000, Tr Loss: 0.0117, Tr Acc: 100.0000, Val Loss: 1.0688, Val Acc: 66.6667\n",
      "Epoch 751/1000, Tr Loss: 0.0084, Tr Acc: 100.0000, Val Loss: 1.0733, Val Acc: 66.6667\n",
      "Epoch 801/1000, Tr Loss: 0.0067, Tr Acc: 100.0000, Val Loss: 1.0868, Val Acc: 66.6667\n",
      "Epoch 851/1000, Tr Loss: 0.0064, Tr Acc: 100.0000, Val Loss: 1.1126, Val Acc: 66.6667\n",
      "Epoch 901/1000, Tr Loss: 0.0058, Tr Acc: 100.0000, Val Loss: 1.1205, Val Acc: 66.6667\n",
      "Epoch 951/1000, Tr Loss: 0.0050, Tr Acc: 100.0000, Val Loss: 1.1424, Val Acc: 66.6667\n"
     ]
    }
   ],
   "source": [
    "from common import train\n",
    "net = ConvNet().cuda(0)\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    gpu_num = 0,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    wand = wand\n",
    "         )\n",
    "\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e963254-e8b4-4a34-b5e0-e9e37f6f620d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "933e1620-4c45-4616-b427-6bb66dae4812",
   "metadata": {},
   "source": [
    "### Validate Findtune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e8341e5-ea95-4ae6-8418-1f792b15c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c0fc2ea-ae32-4a90-a92a-eae5d1effcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet().cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79516f20-09c3-4d57-8a8f-1fd032fc77a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model_find_tune_2class_2ch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cd67654-6054-4d7c-ae64-d9caf2f5f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = create_dataloader(X_vail, y_vail, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b448572-ac9b-439f-b017-dc5525b024a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Acc: 100.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 1\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "old_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    net.eval()\n",
    "    for i, (items, classes) in enumerate(test_loader):\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        \n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(1)\n",
    "            classes = classes.cuda(1)\n",
    "        \n",
    "        outputs = net(items)\n",
    "        loss += criterion(outputs, classes).item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data).sum()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    valid_loss.append(loss/iterations)\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) * 100.0)\n",
    "print (' Val Acc: %.4f'\n",
    "                   %(valid_accuracy[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c743c4d3-58ce-4fd3-8777-09e3ef283e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8a1cb-9cdb-404a-b363-6e568d88261d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
