{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,EEGNetv4,HybridNet,EEGInceptionMI,EEGITNet,ATCNet\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.paradigms import MotorImagery\n",
    "from braindecode.augmentation import FrequencyShift ,GaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    return X,np.array(y_).T\n",
    "def extrack_dataset_types(dataset,types = 'left'):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X[y == 1]\n",
    "    if types == \"foot\":\n",
    "        X = X[y == 2]\n",
    "    if types == \"tongue\":\n",
    "        X = X[y == 3]\n",
    "    return X,y\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),'./{}/{:.4f}_{}_{:.4f}_{:.4f}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1]))\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          vail_loader= None,\n",
    "         labels=None,\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    for i, (items, classes) in enumerate(vail_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    return y_pred,y_true,correct_scalar,valid_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, n_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (end - start) + start\n",
    "    return betas\n",
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
    "    kl = 0.5 * (-1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2) + ((mean1 - mean2) ** 2) * torch.exp(-logvar2))\n",
    "    return kl\n",
    "def approx_standard_normal_cdf(x):\n",
    "    return 0.5 * (1.0 + torch.tanh(torch.tensor(np.sqrt(2.0 / np.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "def discretized_gaussian_log_likelihood(x, means, log_scales):\n",
    "    # Assumes data is integers [0, 255] rescaled to [-1, 1]\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = approx_standard_normal_cdf(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = approx_standard_normal_cdf(min_in)\n",
    "    log_cdf_plus = torch.log(torch.clamp(cdf_plus, min=1e-12))\n",
    "    log_one_minus_cdf_min = torch.log(torch.clamp(1 - cdf_min, min=1e-12))\n",
    "    cdf_delta = cdf_plus - cdf_min\n",
    "    log_probs = torch.where(x < -0.999, log_cdf_plus, torch.where(x > 0.999, log_one_minus_cdf_min, torch.log(torch.clamp(cdf_delta, min=1e-12))))\n",
    "    return log_probs\n",
    "\n",
    "def loss_variational(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # Perform diffusion for step t\n",
    "    x_t = q_sample(x_0, t)\n",
    "    # Compute the true mean and variance\n",
    "    true_mean, true_var = q_posterior_mean_variance(x_0, x_t, t)\n",
    "    # Infer the mean and variance with our model\n",
    "    model_mean, model_var = p_mean_variance(model, x_t, t)\n",
    "    # Compute the KL loss\n",
    "    kl = normal_kl(true_mean, true_var, model_mean, model_var)\n",
    "    kl = torch.mean(kl.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # NLL of the decoder\n",
    "    decoder_nll = -discretized_gaussian_log_likelihood(x_0, means=model_mean, log_scales=0.5 * model_var)\n",
    "    decoder_nll = torch.mean(decoder_nll.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # At the first timestep return the decoder NLL, otherwise return KL(q(x_{t-1}|x_t,x_0) || p(x_{t-1}|x_t))\n",
    "    output = torch.where(t == 0, decoder_nll, kl)\n",
    "    return output.mean(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "\n",
    "def noise_estimation_loss(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # x0 multiplier\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    # eps multiplier\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0)\n",
    "    # model input\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_continuous_noise_level(batch_size):\n",
    "    \"\"\"\n",
    "    Samples continuous noise level.\n",
    "    This is what makes WaveGrad different from other Denoising Diffusion Probabilistic Models.\n",
    "    \"\"\"\n",
    "    t = np.random.choice(range(1, n_steps), size=batch_size)\n",
    "    continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "        np.random.uniform(\n",
    "            alphas_prod_p_sqrt[t-1],\n",
    "            alphas_prod_p_sqrt[t],\n",
    "            size=batch_size\n",
    "        )).cuda(0)\n",
    "    return continuous_sqrt_alpha_cumprod.unsqueeze(-1)\n",
    "\n",
    "def q_sample(x_0, continuous_sqrt_alpha_cumprod=None, eps=None):\n",
    "    batch_size = x_0.shape[0]\n",
    "    if isinstance(eps, type(None)):\n",
    "        continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "        eps = torch.randn_like(x_0).cuda(0)\n",
    "    # Closed form signal diffusion\n",
    "    outputs = continuous_sqrt_alpha_cumprod * x_0 + (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * eps\n",
    "    return outputs\n",
    "\n",
    "def q_posterior(x_start, x, t):\n",
    "    \"\"\" Computes reverse (denoising) process posterior q(y_{t-1}|y_0, y_t, x) \"\"\"\n",
    "    posterior_mean = posterior_mean_coef_1[t].cuda(0) * x_start.cuda(0) + posterior_mean_coef_2[t].cuda(0) * x.cuda(0)\n",
    "    posterior_log_variance_clip = posterior_log_variance_clipped[t]\n",
    "    return posterior_mean, posterior_log_variance_clip\n",
    "\n",
    "def predict_start_from_noise(x, t, eps):\n",
    "    \"\"\" Computes y_0 from given y_t and reconstructed noise. \"\"\"\n",
    "    return sqrt_recip_alphas_cumprod[t] * x - sqrt_alphas_cumprod_m1[t] * eps\n",
    "\n",
    "def p_mean_variance(model, x, t, clip_denoised=True):\n",
    "    \"\"\" Computes Gaussian transitions of Markov chain at step t \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    noise_level = torch.FloatTensor([alphas_prod_p_sqrt[t+1]]).repeat(batch_size, 1).cuda(0)\n",
    "    # Infer noise, conditioned on continuous level\n",
    "\n",
    "    eps_recon = model(x.cuda(0), noise_level)\n",
    "    x_recon = predict_start_from_noise(x.cuda(0), t, eps_recon.cuda(0))\n",
    "    # Output clipping in WaveGrad\n",
    "    if clip_denoised:\n",
    "        x_recon.clamp_(-1.0, 1.0)\n",
    "    model_mean, posterior_log_variance = q_posterior(x_recon, x, t)\n",
    "    return model_mean, posterior_log_variance\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    model_mean, model_log_variance = p_mean_variance(model, x, t)\n",
    "    eps = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "    return model_mean + eps * (0.5 * model_log_variance).exp()\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape).cuda(0)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps - 1)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "def compute_loss(model, x_0):\n",
    "    # Sample continuous noise level\n",
    "    batch_size = x_0.shape[0]\n",
    "    continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "    eps = torch.randn_like(x_0)\n",
    "    # Diffuse the signal\n",
    "    y_noisy = q_sample(x_0, continuous_sqrt_alpha_cumprod, eps)\n",
    "    # Reconstruct the added noise\n",
    "    eps_recon = model(y_noisy, continuous_sqrt_alpha_cumprod)\n",
    "    #print(eps_recon.shape)\n",
    "    loss = torch.nn.L1Loss()(eps_recon, eps)\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.linear_scale = 5e3\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        if len(noise_level.shape) > 1:\n",
    "            noise_level = noise_level.squeeze(-1)\n",
    "        half_dim = self.n_channels // 2\n",
    "        exponents = torch.arange(half_dim, dtype=torch.float32).to(noise_level) / float(half_dim)\n",
    "        exponents = 1e-4 ** exponents\n",
    "        exponents = self.linear_scale * noise_level.unsqueeze(1) * exponents.unsqueeze(0)\n",
    "        return torch.cat([exponents.sin(), exponents.cos()], dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = y\n",
    "        out = gamma * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalConv1d(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConditionalConv1d, self).__init__()\n",
    "        self.conv1d = torch.nn.Conv1d(**kwargs)\n",
    "        self.embedding = PositionalEncoding(kwargs.get('out_channels'))\n",
    "        torch.nn.init.orthogonal_(self.conv1d.weight.data, gain=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.conv1d(x);\n",
    "        gamma = self.embedding(y)\n",
    "        return out * gamma.unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.conv1 = ConditionalConv1d(in_channels=1, out_channels=64, kernel_size=16, padding=8)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = ConditionalConv1d(in_channels=64, out_channels=64, kernel_size=16, padding=16, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=16, padding=16, dilation=2)\n",
    "        self.lin1 = ConditionalLinear(1130, 2260)\n",
    "        self.lin2 = nn.Linear(2260, 1125)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = x.squeeze(1)\n",
    "        #print(x.shape)\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        return self.lin2(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    }
   ],
   "source": [
    "subjects = list(range(1,10))\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 35.  # high cut frequency for filtering\n",
    "resample = 128\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "preprocessors = [\n",
    "                    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "                    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "                    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "                    #Preprocessor('resample', sfreq=resample),\n",
    "                    Preprocessor(exponential_moving_standardize,  # Exponential movin standardization\n",
    "                                factor_new=factor_new,\n",
    "                                 init_block_size=init_block_size)\n",
    "                    ]\n",
    "n_epochs = 5000\n",
    "lr = 1 * 0.0001\n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for subject_id in subjects:\n",
    "\n",
    "    transform = GaussianNoise(\n",
    "    probability=1.,std=0.1\n",
    ")\n",
    "    X_syntheic = np.load(\"Synthetic_data_V2/X_subject_{0}_72_['left', 'right', 'foot', 'tongue'].npy\".format(subject_id))\n",
    "    y_syntheic = np.load(\"Synthetic_data_V2/X_subject_{0}_72_['left', 'right', 'foot', 'tongue'].npy\".format(subject_id))\n",
    "    X_shift, _ = transform.operation(torch.as_tensor(X_syntheic).float(), None,std=0.1)\n",
    "    np.save(\"Synthetic_data_Gnoise/X_subject_{0}_from_diff.npy\".format(subject_id),X_shift)\n",
    "    np.save(\"Synthetic_data_Gnoise/y_subject_{0}_from_diff.npy\".format(subject_id),y_syntheic)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
