{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,EEGNetv4,HybridNet,EEGInceptionMI,EEGITNet,ATCNet\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.paradigms import MotorImagery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    return X,np.array(y_).T\n",
    "def extrack_dataset_types(dataset,types = 'left'):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X[y == 1]\n",
    "    if types == \"foot\":\n",
    "        X = X[y == 2]\n",
    "    if types == \"tongue\":\n",
    "        X = X[y == 3]\n",
    "    return X,y\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),'./{}/{:.4f}_{}_{:.4f}_{:.4f}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1]))\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          vail_loader= None,\n",
    "         labels=None,\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    for i, (items, classes) in enumerate(vail_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    return y_pred,y_true,correct_scalar,valid_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, n_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (end - start) + start\n",
    "    return betas\n",
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
    "    kl = 0.5 * (-1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2) + ((mean1 - mean2) ** 2) * torch.exp(-logvar2))\n",
    "    return kl\n",
    "def approx_standard_normal_cdf(x):\n",
    "    return 0.5 * (1.0 + torch.tanh(torch.tensor(np.sqrt(2.0 / np.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "def discretized_gaussian_log_likelihood(x, means, log_scales):\n",
    "    # Assumes data is integers [0, 255] rescaled to [-1, 1]\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = approx_standard_normal_cdf(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = approx_standard_normal_cdf(min_in)\n",
    "    log_cdf_plus = torch.log(torch.clamp(cdf_plus, min=1e-12))\n",
    "    log_one_minus_cdf_min = torch.log(torch.clamp(1 - cdf_min, min=1e-12))\n",
    "    cdf_delta = cdf_plus - cdf_min\n",
    "    log_probs = torch.where(x < -0.999, log_cdf_plus, torch.where(x > 0.999, log_one_minus_cdf_min, torch.log(torch.clamp(cdf_delta, min=1e-12))))\n",
    "    return log_probs\n",
    "\n",
    "def loss_variational(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # Perform diffusion for step t\n",
    "    x_t = q_sample(x_0, t)\n",
    "    # Compute the true mean and variance\n",
    "    true_mean, true_var = q_posterior_mean_variance(x_0, x_t, t)\n",
    "    # Infer the mean and variance with our model\n",
    "    model_mean, model_var = p_mean_variance(model, x_t, t)\n",
    "    # Compute the KL loss\n",
    "    kl = normal_kl(true_mean, true_var, model_mean, model_var)\n",
    "    kl = torch.mean(kl.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # NLL of the decoder\n",
    "    decoder_nll = -discretized_gaussian_log_likelihood(x_0, means=model_mean, log_scales=0.5 * model_var)\n",
    "    decoder_nll = torch.mean(decoder_nll.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # At the first timestep return the decoder NLL, otherwise return KL(q(x_{t-1}|x_t,x_0) || p(x_{t-1}|x_t))\n",
    "    output = torch.where(t == 0, decoder_nll, kl)\n",
    "    return output.mean(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "\n",
    "def noise_estimation_loss(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # x0 multiplier\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    # eps multiplier\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0)\n",
    "    # model input\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_continuous_noise_level(batch_size):\n",
    "    \"\"\"\n",
    "    Samples continuous noise level.\n",
    "    This is what makes WaveGrad different from other Denoising Diffusion Probabilistic Models.\n",
    "    \"\"\"\n",
    "    t = np.random.choice(range(1, n_steps), size=batch_size)\n",
    "    continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "        np.random.uniform(\n",
    "            alphas_prod_p_sqrt[t-1],\n",
    "            alphas_prod_p_sqrt[t],\n",
    "            size=batch_size\n",
    "        )).cuda(0)\n",
    "    return continuous_sqrt_alpha_cumprod.unsqueeze(-1)\n",
    "\n",
    "def q_sample(x_0, continuous_sqrt_alpha_cumprod=None, eps=None):\n",
    "    batch_size = x_0.shape[0]\n",
    "    if isinstance(eps, type(None)):\n",
    "        continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "        eps = torch.randn_like(x_0).cuda(0)\n",
    "    # Closed form signal diffusion\n",
    "    outputs = continuous_sqrt_alpha_cumprod * x_0 + (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * eps\n",
    "    return outputs\n",
    "\n",
    "def q_posterior(x_start, x, t):\n",
    "    \"\"\" Computes reverse (denoising) process posterior q(y_{t-1}|y_0, y_t, x) \"\"\"\n",
    "    posterior_mean = posterior_mean_coef_1[t].cuda(0) * x_start.cuda(0) + posterior_mean_coef_2[t].cuda(0) * x.cuda(0)\n",
    "    posterior_log_variance_clip = posterior_log_variance_clipped[t]\n",
    "    return posterior_mean, posterior_log_variance_clip\n",
    "\n",
    "def predict_start_from_noise(x, t, eps):\n",
    "    \"\"\" Computes y_0 from given y_t and reconstructed noise. \"\"\"\n",
    "    return sqrt_recip_alphas_cumprod[t] * x - sqrt_alphas_cumprod_m1[t] * eps\n",
    "\n",
    "def p_mean_variance(model, x, t, clip_denoised=True):\n",
    "    \"\"\" Computes Gaussian transitions of Markov chain at step t \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    noise_level = torch.FloatTensor([alphas_prod_p_sqrt[t+1]]).repeat(batch_size, 1).cuda(0)\n",
    "    # Infer noise, conditioned on continuous level\n",
    "\n",
    "    eps_recon = model(x.cuda(0), noise_level)\n",
    "    x_recon = predict_start_from_noise(x.cuda(0), t, eps_recon.cuda(0))\n",
    "    # Output clipping in WaveGrad\n",
    "    if clip_denoised:\n",
    "        x_recon.clamp_(-1.0, 1.0)\n",
    "    model_mean, posterior_log_variance = q_posterior(x_recon, x, t)\n",
    "    return model_mean, posterior_log_variance\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    model_mean, model_log_variance = p_mean_variance(model, x, t)\n",
    "    eps = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "    return model_mean + eps * (0.5 * model_log_variance).exp()\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape).cuda(0)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps - 1)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "def compute_loss(model, x_0):\n",
    "    # Sample continuous noise level\n",
    "    batch_size = x_0.shape[0]\n",
    "    continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "    eps = torch.randn_like(x_0)\n",
    "    # Diffuse the signal\n",
    "    y_noisy = q_sample(x_0, continuous_sqrt_alpha_cumprod, eps)\n",
    "    # Reconstruct the added noise\n",
    "    eps_recon = model(y_noisy, continuous_sqrt_alpha_cumprod)\n",
    "    #print(eps_recon.shape)\n",
    "    loss = torch.nn.L1Loss()(eps_recon, eps)\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    return X,np.array(y_).T\n",
    "def extrack_dataset_types(dataset,types = 'left'):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X[y == 1]\n",
    "    if types == \"foot\":\n",
    "        X = X[y == 2]\n",
    "    if types == \"tongue\":\n",
    "        X = X[y == 3]\n",
    "    return X,y\n",
    "\n",
    "def extrack_online_dataset_types(X_old,y_old,types = 'left'):\n",
    "\n",
    "    x_shape = X_old.shape\n",
    "    y_shape = y_old.shape[0]\n",
    "\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X_old[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X_old[y == 1]\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),'./{}/{:.4f}_{}_{:.4f}_{:.4f}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1]))\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          vail_loader= None,\n",
    "         labels=None,\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    for i, (items, classes) in enumerate(vail_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    return y_pred,y_true,correct_scalar,valid_accuracy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, n_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (end - start) + start\n",
    "    return betas\n",
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
    "    kl = 0.5 * (-1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2) + ((mean1 - mean2) ** 2) * torch.exp(-logvar2))\n",
    "    return kl\n",
    "def approx_standard_normal_cdf(x):\n",
    "    return 0.5 * (1.0 + torch.tanh(torch.tensor(np.sqrt(2.0 / np.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "def discretized_gaussian_log_likelihood(x, means, log_scales):\n",
    "    # Assumes data is integers [0, 255] rescaled to [-1, 1]\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = approx_standard_normal_cdf(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = approx_standard_normal_cdf(min_in)\n",
    "    log_cdf_plus = torch.log(torch.clamp(cdf_plus, min=1e-12))\n",
    "    log_one_minus_cdf_min = torch.log(torch.clamp(1 - cdf_min, min=1e-12))\n",
    "    cdf_delta = cdf_plus - cdf_min\n",
    "    log_probs = torch.where(x < -0.999, log_cdf_plus, torch.where(x > 0.999, log_one_minus_cdf_min, torch.log(torch.clamp(cdf_delta, min=1e-12))))\n",
    "    return log_probs\n",
    "\n",
    "def loss_variational(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # Perform diffusion for step t\n",
    "    x_t = q_sample(x_0, t)\n",
    "    # Compute the true mean and variance\n",
    "    true_mean, true_var = q_posterior_mean_variance(x_0, x_t, t)\n",
    "    # Infer the mean and variance with our model\n",
    "    model_mean, model_var = p_mean_variance(model, x_t, t)\n",
    "    # Compute the KL loss\n",
    "    kl = normal_kl(true_mean, true_var, model_mean, model_var)\n",
    "    kl = torch.mean(kl.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # NLL of the decoder\n",
    "    decoder_nll = -discretized_gaussian_log_likelihood(x_0, means=model_mean, log_scales=0.5 * model_var)\n",
    "    decoder_nll = torch.mean(decoder_nll.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # At the first timestep return the decoder NLL, otherwise return KL(q(x_{t-1}|x_t,x_0) || p(x_{t-1}|x_t))\n",
    "    output = torch.where(t == 0, decoder_nll, kl)\n",
    "    return output.mean(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "\n",
    "def noise_estimation_loss(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # x0 multiplier\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    # eps multiplier\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0)\n",
    "    # model input\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_continuous_noise_level(batch_size):\n",
    "    \"\"\"\n",
    "    Samples continuous noise level.\n",
    "    This is what makes WaveGrad different from other Denoising Diffusion Probabilistic Models.\n",
    "    \"\"\"\n",
    "    t = np.random.choice(range(1, n_steps), size=batch_size)\n",
    "    continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "        np.random.uniform(\n",
    "            alphas_prod_p_sqrt[t-1],\n",
    "            alphas_prod_p_sqrt[t],\n",
    "            size=batch_size\n",
    "        )).cuda(0)\n",
    "    return continuous_sqrt_alpha_cumprod.unsqueeze(-1)\n",
    "\n",
    "def q_sample(x_0, continuous_sqrt_alpha_cumprod=None, eps=None):\n",
    "    batch_size = x_0.shape[0]\n",
    "    if isinstance(eps, type(None)):\n",
    "        continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "        eps = torch.randn_like(x_0).cuda(0)\n",
    "    # Closed form signal diffusion\n",
    "    outputs = continuous_sqrt_alpha_cumprod * x_0 + (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * eps\n",
    "    return outputs\n",
    "\n",
    "def q_posterior(x_start, x, t):\n",
    "    \"\"\" Computes reverse (denoising) process posterior q(y_{t-1}|y_0, y_t, x) \"\"\"\n",
    "    posterior_mean = posterior_mean_coef_1[t] * x_start + posterior_mean_coef_2[t] * x\n",
    "    posterior_log_variance_clip = posterior_log_variance_clipped[t]\n",
    "    return posterior_mean, posterior_log_variance_clip\n",
    "\n",
    "def predict_start_from_noise(x, t, eps):\n",
    "    \"\"\" Computes y_0 from given y_t and reconstructed noise. \"\"\"\n",
    "    return sqrt_recip_alphas_cumprod[t] * x - sqrt_alphas_cumprod_m1[t] * eps\n",
    "\n",
    "def p_mean_variance(model, x, t, clip_denoised=True):\n",
    "    \"\"\" Computes Gaussian transitions of Markov chain at step t \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    noise_level = torch.FloatTensor([alphas_prod_p_sqrt[t+1]]).repeat(batch_size, 1).cuda(0)\n",
    "    # Infer noise, conditioned on continuous level\n",
    "    eps_recon = model(x, noise_level)\n",
    "    x_recon = predict_start_from_noise(x, t, eps_recon)\n",
    "    # Output clipping in WaveGrad\n",
    "    if clip_denoised:\n",
    "        x_recon.clamp_(-1.0, 1.0)\n",
    "    model_mean, posterior_log_variance = q_posterior(x_recon, x, t)\n",
    "    return model_mean, posterior_log_variance\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    model_mean, model_log_variance = p_mean_variance(model, x, t)\n",
    "    eps = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "    return model_mean + eps * (0.5 * model_log_variance).exp()\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape).cuda(0)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps - 1)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "def compute_loss(model, x_0):\n",
    "    # Sample continuous noise level\n",
    "    batch_size = x_0.shape[0]\n",
    "    continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "    eps = torch.randn_like(x_0)\n",
    "    # Diffuse the signal\n",
    "    y_noisy = q_sample(x_0, continuous_sqrt_alpha_cumprod, eps)\n",
    "    # Reconstruct the added noise\n",
    "    eps_recon = model(y_noisy, continuous_sqrt_alpha_cumprod)\n",
    "    print(eps_recon.shape)\n",
    "    loss = torch.nn.L1Loss()(eps_recon, eps)\n",
    "    return loss\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.linear_scale = 5e3\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        if len(noise_level.shape) > 1:\n",
    "            noise_level = noise_level.squeeze(-1)\n",
    "        half_dim = self.n_channels // 2\n",
    "        exponents = torch.arange(half_dim, dtype=torch.float32).to(noise_level) / float(half_dim)\n",
    "        exponents = 1e-4 ** exponents\n",
    "        exponents = self.linear_scale * noise_level.unsqueeze(1) * exponents.unsqueeze(0)\n",
    "        return torch.cat([exponents.sin(), exponents.cos()], dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = y\n",
    "        out = gamma * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalConv1d(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConditionalConv1d, self).__init__()\n",
    "        self.conv1d = torch.nn.Conv1d(**kwargs)\n",
    "        self.embedding = PositionalEncoding(kwargs.get('out_channels'))\n",
    "        torch.nn.init.orthogonal_(self.conv1d.weight.data, gain=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.conv1d(x);\n",
    "        gamma = self.embedding(y)\n",
    "        return out * gamma.unsqueeze(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.conv1 = ConditionalConv1d(in_channels=1, out_channels=64, kernel_size=16, padding=8)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = ConditionalConv1d(in_channels=64, out_channels=64, kernel_size=16, padding=16, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=16, padding=16, dilation=2)\n",
    "        self.lin1 = ConditionalLinear(1756, 3512)\n",
    "\n",
    "        self.lin2 = nn.Linear(3512, 1751)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = x.squeeze(1)\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        return self.lin2(x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "n_steps = 1000\n",
    "betas = make_beta_schedule(schedule='sigmoid', n_timesteps=n_steps, start=1e-6, end=1e-2)\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_prod_p_sqrt = alphas_prod_p.sqrt()\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "sqrt_recip_alphas_cumprod = (1 / alphas_prod).sqrt()\n",
    "sqrt_alphas_cumprod_m1 = (1 - alphas_prod).sqrt() * sqrt_recip_alphas_cumprod\n",
    "posterior_mean_coef_1 = (betas * torch.sqrt(alphas_prod_p) / (1 - alphas_prod))\n",
    "posterior_mean_coef_2 = ((1 - alphas_prod_p) * torch.sqrt(alphas) / (1 - alphas_prod))\n",
    "posterior_variance = betas * (1 - alphas_prod_p) / (1 - alphas_prod)\n",
    "posterior_log_variance_clipped = torch.log(torch.cat((posterior_variance[1].view(1, 1), posterior_variance[1:].view(-1, 1)), 0)).view(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_gen : 72\n",
      "types  : left of [20]\n",
      "types  : right of [20]\n",
      "Done Synthetic data of subject [20]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1000\n",
    "#types_list = ['left','right','foot','tongue',]\n",
    "types_list = ['left','right']\n",
    "\n",
    "#subject_list = list(range(2,10))\n",
    "subject_list = [[20]]\n",
    "size_gen_list = [72]\n",
    "\n",
    "#   288 , 22 , 1125\n",
    "for size_gen in size_gen_list :\n",
    "    print(\"size_gen : {}\".format(size_gen))\n",
    "    y = np.zeros((size_gen*(len(types_list)),))\n",
    "    x_seq = np.zeros((size_gen*(len(types_list)),8,1751))\n",
    "    for subject in subject_list:\n",
    "        for types_num in range(len(types_list)):\n",
    "\n",
    "            types = types_list[types_num]\n",
    "            print(\"types  : {0} of {1}\".format(types , subject))\n",
    "            #print(\"types_num : {}\".format(types_num))\n",
    "            for i in range(8):\n",
    "                for j in range(size_gen):\n",
    "                    model = ConditionalModel(n_steps).cuda(0)\n",
    "                    #print('diffusion/{0}_{1}_{2}'.format(subject,i,types))\n",
    "                    model.load_state_dict(torch.load('diffusion_online/{0}_{1}_{2}_V2'.format(subject,i,types)))\n",
    "                    cur_x = torch.randn([1, 1751]).cuda(0)\n",
    "                    cur_x = p_sample(model, cur_x,998)\n",
    "                    #cur_x.shape\n",
    "                    if types_num == 0 :\n",
    "                        x_seq[j][i]= cur_x.cpu().detach().numpy()\n",
    "                        if types == 'left':\n",
    "                            y[j] = 0\n",
    "                        if types == 'right':\n",
    "                            y[j] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        #print(\"types_num : {}\".format(types_num))\n",
    "                    if types_num == 1 or types_num == 2 or types_num == 3:\n",
    "                        x_seq[(size_gen*types_num)+j][i]= cur_x.cpu().detach().numpy()\n",
    "                        y[(size_gen*types_num)+j] = types_num\n",
    "        np.save(\"Synthetic_data_online/X_subject_{0}_{1}_{2}_v2.npy\".format(subject,size_gen,types_list),x_seq)\n",
    "        np.save(\"Synthetic_data_online/y_subject_{0}_{1}_{2}_v2.npy\".format(subject,size_gen,types_list),y)\n",
    "        print(\"Done Synthetic data of subject {}\".format(subject))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##############################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "for size_gen in size_gen_list :\n",
    "    print(\"size_gen : {}\".format(size_gen))\n",
    "    y = np.zeros((size_gen*4,))\n",
    "    x_seq = np.zeros((size_gen*4,22,1125))\n",
    "    for subject in subject_list:\n",
    "        for types_num in range(1):\n",
    "            types = types_list[types_num]\n",
    "            print(\"types  : {0} of {1}\".format(types , subject))\n",
    "            #print(\"types_num : {}\".format(types_num))\n",
    "            for i in range(22):\n",
    "                for j in range(size_gen):\n",
    "                    model = ConditionalModel(n_steps).cuda(0)\n",
    "                    print('diffusion/{0}_{1}_{2}'.format(subject,i,types))\n",
    "                    model.load_state_dict(torch.load('diffusion/{0}_{1}_{2}'.format(subject,i,types)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# only 1 CH\n",
    "\n",
    "\n",
    "n_steps = 1000\n",
    "#types_list = ['left','right','foot','tongue',]\n",
    "types_list = ['foot']\n",
    "\n",
    "subject_list = [3]#list(range(1,10))\n",
    "\n",
    "size_gen_list = [72]#[18,36,54,72]\n",
    "\n",
    "#   288 , 22 , 1125\n",
    "for size_gen in size_gen_list :\n",
    "    print(\"size_gen : {}\".format(size_gen))\n",
    "    y = np.zeros((size_gen*(len(types_list)),))\n",
    "    x_seq = np.zeros((size_gen*(len(types_list)),1,1125))\n",
    "    for subject in subject_list:\n",
    "        for types_num in range(len(types_list)):\n",
    "\n",
    "            types = types_list[types_num]\n",
    "            print(\"types  : {0} of {1}\".format(types , subject))\n",
    "            #print(\"types_num : {}\".format(types_num))\n",
    "            for i in [0]:#range(22):\n",
    "                for j in range(size_gen):\n",
    "                    model = ConditionalModel(n_steps).cuda(0)\n",
    "                    #print('diffusion/{0}_{1}_{2}'.format(subject,i,types))\n",
    "                    model.load_state_dict(torch.load('diffusion/{0}_{1}_{2}'.format(subject,i,types)))\n",
    "                    cur_x = torch.randn([1, 1125]).cuda(0)\n",
    "                    cur_x = p_sample(model, cur_x,998)\n",
    "                    #cur_x.shape\n",
    "                    if types_num == 0 :\n",
    "                        x_seq[j][i]= cur_x.cpu().detach().numpy()\n",
    "                        y[j] = types_num\n",
    "\n",
    "                        #print(\"types_num : {}\".format(types_num))\n",
    "                    if types_num == 1 or types_num == 2 or types_num == 3:\n",
    "                        x_seq[(size_gen*types_num)+j][i]= cur_x.cpu().detach().numpy()\n",
    "                        y[(size_gen*types_num)+j] = types_num\n",
    "        np.save(\"Synthetic_data_all/X_subject_{0}_{1}_{2}_1ch.npy\".format(subject,size_gen,types_list),x_seq)\n",
    "        #np.save(\"Synthetic_data_all/y_subject_{0}_{1}_{2}.npy\".format(subject,size_gen,types_list),y)\n",
    "        print(\"Done Synthetic data of subject {}\".format(subject))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from ignite.metrics import FID, InceptionScore\n",
    "import os\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "# create default evaluator for doctests\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "default_model = nn.Sequential(OrderedDict([\n",
    "    ('base', nn.Linear(4, 2)),\n",
    "    ('fc', nn.Linear(2, 1))\n",
    "]))\n",
    "\n",
    "manual_seed(666)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X=np.load(\"Synthetic_data_all/X_subject_1_72_['foot']_1ch.npy\")\n",
    "t = torch.from_numpy(X)\n",
    "y = torch.rand(10, 3, 299, 299)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([72, 1, 1125])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nutapolt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Current run is terminating due to exception: Inputs should be a tensor of dim 4, got 3\n",
      "Engine run is terminating due to exception: Inputs should be a tensor of dim 4, got 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs should be a tensor of dim 4, got 3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [12], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m metric \u001B[38;5;241m=\u001B[39m InceptionScore()\n\u001B[1;32m      2\u001B[0m metric\u001B[38;5;241m.\u001B[39mattach(default_evaluator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_evaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(state\u001B[38;5;241m.\u001B[39mmetrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001B[0m, in \u001B[0;36mEngine.run\u001B[0;34m(self, data, max_epochs, epoch_length, seed)\u001B[0m\n\u001B[1;32m    701\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch_length should be provided if data is None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mdataloader \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m--> 704\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001B[0m, in \u001B[0;36mEngine._internal_run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine run is terminating due to exception: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 783\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    785\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001B[0m, in \u001B[0;36mEngine._handle_exception\u001B[0;34m(self, e)\u001B[0m\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mEXCEPTION_RAISED, e)\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 466\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001B[0m, in \u001B[0;36mEngine._internal_run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    750\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    751\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_engine()\n\u001B[0;32m--> 753\u001B[0m time_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_once_on_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;66;03m# time is available for handlers but must be update after fire\u001B[39;00m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mtimes[Events\u001B[38;5;241m.\u001B[39mEPOCH_COMPLETED\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m time_taken\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:854\u001B[0m, in \u001B[0;36mEngine._run_once_on_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent run is terminating due to exception: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 854\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001B[0m, in \u001B[0;36mEngine._handle_exception\u001B[0;34m(self, e)\u001B[0m\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mEXCEPTION_RAISED, e)\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 466\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:841\u001B[0m, in \u001B[0;36mEngine._run_once_on_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_STARTED)\n\u001B[1;32m    840\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_function(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbatch)\n\u001B[0;32m--> 841\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fire_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvents\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mITERATION_COMPLETED\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshould_terminate \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshould_terminate_single_epoch:\n\u001B[1;32m    844\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mTERMINATE_SINGLE_EPOCH, iter_counter\u001B[38;5;241m=\u001B[39miter_counter)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/engine/engine.py:421\u001B[0m, in \u001B[0;36mEngine._fire_event\u001B[0;34m(self, event_name, *event_args, **event_kwargs)\u001B[0m\n\u001B[1;32m    419\u001B[0m kwargs\u001B[38;5;241m.\u001B[39mupdate(event_kwargs)\n\u001B[1;32m    420\u001B[0m first, others \u001B[38;5;241m=\u001B[39m ((args[\u001B[38;5;241m0\u001B[39m],), args[\u001B[38;5;241m1\u001B[39m:]) \u001B[38;5;28;01mif\u001B[39;00m (args \u001B[38;5;129;01mand\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m ((), args)\n\u001B[0;32m--> 421\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mevent_args\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mothers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/metrics/metric.py:311\u001B[0m, in \u001B[0;36mMetric.iteration_completed\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate((tensor_o1, tensor_o2))\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 311\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/metrics/metric.py:596\u001B[0m, in \u001B[0;36mreinit__is_reduced.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m: Metric, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m     \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_reduced \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/metrics/gan/inception_score.py:114\u001B[0m, in \u001B[0;36mInceptionScore.update\u001B[0;34m(self, output)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;129m@reinit__is_reduced\u001B[39m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, output: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 114\u001B[0m     probabilities \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m     prob_sum \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(probabilities, \u001B[38;5;241m0\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m    117\u001B[0m     log_prob \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(probabilities \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eps)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/metrics/gan/utils.py:93\u001B[0m, in \u001B[0;36m_BaseInceptionMetric._extract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     90\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_device)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 93\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_feature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_feature_shapes(outputs)\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/ignite/metrics/gan/utils.py:36\u001B[0m, in \u001B[0;36mInceptionModel.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m---> 36\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInputs should be a tensor of dim 4, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInputs should be a tensor with 3 channels, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Inputs should be a tensor of dim 4, got 3"
     ]
    }
   ],
   "source": [
    "metric = InceptionScore()\n",
    "metric.attach(default_evaluator, \"is\")\n",
    "\n",
    "state = default_evaluator.run([t])\n",
    "print(state.metrics[\"is\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = InceptionScore(num_features=1, feature_extractor=default_model)\n",
    "metric.attach(default_evaluator, \"is\")\n",
    "y = torch.zeros(10, 4)\n",
    "state = default_evaluator.run([y])\n",
    "print(state.metrics[\"is\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
