{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,EEGNetv4,HybridNet,EEGInceptionMI,EEGITNet,ATCNet\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.paradigms import MotorImagery\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utility import EEG_fif\n",
    "from utility import create_dataloader\n",
    "from utility import multi_network\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    return X,np.array(y_).T\n",
    "def extrack_dataset_types(dataset,types = 'left'):\n",
    "    for x, y, window_ind in dataset:\n",
    "\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X[y == 1]\n",
    "    if types == \"foot\":\n",
    "        X = X[y == 2]\n",
    "    if types == \"tongue\":\n",
    "        X = X[y == 3]\n",
    "    return X,y\n",
    "\n",
    "def extrack_online_dataset_types(X_old,y_old,types = 'left'):\n",
    "\n",
    "    x_shape = X_old.shape\n",
    "    y_shape = y_old.shape[0]\n",
    "\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "\n",
    "    if types == \"left\":\n",
    "        X = X_old[y == 0]\n",
    "    if types == \"right\":\n",
    "        X = X_old[y == 1]\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),'./{}/{:.4f}_{}_{:.4f}_{:.4f}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1]))\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          vail_loader= None,\n",
    "         labels=None,\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    for i, (items, classes) in enumerate(vail_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    return y_pred,y_true,correct_scalar,valid_accuracy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, n_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (end - start) + start\n",
    "    return betas\n",
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
    "    kl = 0.5 * (-1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2) + ((mean1 - mean2) ** 2) * torch.exp(-logvar2))\n",
    "    return kl\n",
    "def approx_standard_normal_cdf(x):\n",
    "    return 0.5 * (1.0 + torch.tanh(torch.tensor(np.sqrt(2.0 / np.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "def discretized_gaussian_log_likelihood(x, means, log_scales):\n",
    "    # Assumes data is integers [0, 255] rescaled to [-1, 1]\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = approx_standard_normal_cdf(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = approx_standard_normal_cdf(min_in)\n",
    "    log_cdf_plus = torch.log(torch.clamp(cdf_plus, min=1e-12))\n",
    "    log_one_minus_cdf_min = torch.log(torch.clamp(1 - cdf_min, min=1e-12))\n",
    "    cdf_delta = cdf_plus - cdf_min\n",
    "    log_probs = torch.where(x < -0.999, log_cdf_plus, torch.where(x > 0.999, log_one_minus_cdf_min, torch.log(torch.clamp(cdf_delta, min=1e-12))))\n",
    "    return log_probs\n",
    "\n",
    "def loss_variational(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # Perform diffusion for step t\n",
    "    x_t = q_sample(x_0, t)\n",
    "    # Compute the true mean and variance\n",
    "    true_mean, true_var = q_posterior_mean_variance(x_0, x_t, t)\n",
    "    # Infer the mean and variance with our model\n",
    "    model_mean, model_var = p_mean_variance(model, x_t, t)\n",
    "    # Compute the KL loss\n",
    "    kl = normal_kl(true_mean, true_var, model_mean, model_var)\n",
    "    kl = torch.mean(kl.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # NLL of the decoder\n",
    "    decoder_nll = -discretized_gaussian_log_likelihood(x_0, means=model_mean, log_scales=0.5 * model_var)\n",
    "    decoder_nll = torch.mean(decoder_nll.view(batch_size, -1), dim=1) / np.log(2.)\n",
    "    # At the first timestep return the decoder NLL, otherwise return KL(q(x_{t-1}|x_t,x_0) || p(x_{t-1}|x_t))\n",
    "    output = torch.where(t == 0, decoder_nll, kl)\n",
    "    return output.mean(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(2, 128, n_steps)\n",
    "        self.lin2 = ConditionalLinear(128, 128, n_steps)\n",
    "        self.lin3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "\n",
    "def noise_estimation_loss(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,))\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "    # x0 multiplier\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    # eps multiplier\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0)\n",
    "    # model input\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_continuous_noise_level(batch_size):\n",
    "    \"\"\"\n",
    "    Samples continuous noise level.\n",
    "    This is what makes WaveGrad different from other Denoising Diffusion Probabilistic Models.\n",
    "    \"\"\"\n",
    "    t = np.random.choice(range(1, n_steps), size=batch_size)\n",
    "    continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "        np.random.uniform(\n",
    "            alphas_prod_p_sqrt[t-1],\n",
    "            alphas_prod_p_sqrt[t],\n",
    "            size=batch_size\n",
    "        )).cuda(0)\n",
    "    return continuous_sqrt_alpha_cumprod.unsqueeze(-1)\n",
    "\n",
    "def q_sample(x_0, continuous_sqrt_alpha_cumprod=None, eps=None):\n",
    "    batch_size = x_0.shape[0]\n",
    "    if isinstance(eps, type(None)):\n",
    "        continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "        eps = torch.randn_like(x_0).cuda(0)\n",
    "    # Closed form signal diffusion\n",
    "    outputs = continuous_sqrt_alpha_cumprod * x_0 + (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * eps\n",
    "    return outputs\n",
    "\n",
    "def q_posterior(x_start, x, t):\n",
    "    \"\"\" Computes reverse (denoising) process posterior q(y_{t-1}|y_0, y_t, x) \"\"\"\n",
    "    posterior_mean = posterior_mean_coef_1[t] * x_start + posterior_mean_coef_2[t] * x\n",
    "    posterior_log_variance_clip = posterior_log_variance_clipped[t]\n",
    "    return posterior_mean, posterior_log_variance_clip\n",
    "\n",
    "def predict_start_from_noise(x, t, eps):\n",
    "    \"\"\" Computes y_0 from given y_t and reconstructed noise. \"\"\"\n",
    "    return sqrt_recip_alphas_cumprod[t] * x - sqrt_alphas_cumprod_m1[t] * eps\n",
    "\n",
    "def p_mean_variance(model, x, t, clip_denoised=True):\n",
    "    \"\"\" Computes Gaussian transitions of Markov chain at step t \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    noise_level = torch.FloatTensor([alphas_prod_p_sqrt[t+1]]).repeat(batch_size, 1).cuda(0)\n",
    "    # Infer noise, conditioned on continuous level\n",
    "    eps_recon = model(x, noise_level)\n",
    "    x_recon = predict_start_from_noise(x, t, eps_recon)\n",
    "    # Output clipping in WaveGrad\n",
    "    if clip_denoised:\n",
    "        x_recon.clamp_(-1.0, 1.0)\n",
    "    model_mean, posterior_log_variance = q_posterior(x_recon, x, t)\n",
    "    return model_mean, posterior_log_variance\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    model_mean, model_log_variance = p_mean_variance(model, x, t)\n",
    "    eps = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "    return model_mean + eps * (0.5 * model_log_variance).exp()\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape).cuda(0)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps - 1)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "def compute_loss(model, x_0):\n",
    "    # Sample continuous noise level\n",
    "    batch_size = x_0.shape[0]\n",
    "    continuous_sqrt_alpha_cumprod = sample_continuous_noise_level(batch_size)\n",
    "    eps = torch.randn_like(x_0)\n",
    "    # Diffuse the signal\n",
    "    y_noisy = q_sample(x_0, continuous_sqrt_alpha_cumprod, eps)\n",
    "    # Reconstruct the added noise\n",
    "    eps_recon = model(y_noisy, continuous_sqrt_alpha_cumprod)\n",
    "    print(eps_recon.shape)\n",
    "    loss = torch.nn.L1Loss()(eps_recon, eps)\n",
    "    return loss\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.linear_scale = 5e3\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        if len(noise_level.shape) > 1:\n",
    "            noise_level = noise_level.squeeze(-1)\n",
    "        half_dim = self.n_channels // 2\n",
    "        exponents = torch.arange(half_dim, dtype=torch.float32).to(noise_level) / float(half_dim)\n",
    "        exponents = 1e-4 ** exponents\n",
    "        exponents = self.linear_scale * noise_level.unsqueeze(1) * exponents.unsqueeze(0)\n",
    "        return torch.cat([exponents.sin(), exponents.cos()], dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = y\n",
    "        out = gamma * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalConv1d(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConditionalConv1d, self).__init__()\n",
    "        self.conv1d = torch.nn.Conv1d(**kwargs)\n",
    "        self.embedding = PositionalEncoding(kwargs.get('out_channels'))\n",
    "        torch.nn.init.orthogonal_(self.conv1d.weight.data, gain=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.conv1d(x);\n",
    "        gamma = self.embedding(y)\n",
    "        return out * gamma.unsqueeze(-1)\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.conv1 = ConditionalConv1d(in_channels=1, out_channels=64, kernel_size=16, padding=8)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = ConditionalConv1d(in_channels=64, out_channels=64, kernel_size=16, padding=16, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=16, padding=16, dilation=2)\n",
    "        self.lin1 = ConditionalLinear(1756, 3512)\n",
    "\n",
    "        self.lin2 = nn.Linear(3512, 1751)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x, y)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = x.squeeze(1)\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        return self.lin2(x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg_mi\n"
     ]
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = 'eeg_mi'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "#runs = [4, 6, 8, 10, 12,14]\n",
    "#runs = [3,5,7,9,11,13]\n",
    "#runs = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "\n",
    "#runs=[3]\n",
    "runs = [3,5,7,9]\n",
    "#runs = [4,6,8,10]\n",
    "#runs = [3,5,7,9,4,6,8,10]\n",
    "subjects = [20]\n",
    "\n",
    "print(path)\n",
    "\n",
    "\n",
    "n_epochs = 5000\n",
    "n_steps = 1000\n",
    "dataset_name=\"S20\"\n",
    "types_list = ['left']\n",
    "load =  False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/AitBrainLab/Diffusion/e/DIFFUSION-2577\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "eeg_mi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R03.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R05.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R07.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R09.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 4 contiguous segments\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R03.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R05.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R07.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/home/nutapolt/utility.py:628: RuntimeWarning: This filename (eeg_mi/S020/S020R09.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 events found\n",
      "Event IDs: [1 2 4]\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 120 events and 1751 original time points ...\n",
      "4 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/utility.py:658: RuntimeWarning: No matching events found for 3 (event id 3)\n",
      "  epochs = mne.Epochs(\n",
      "/tmp/ipykernel_493272/2858261725.py:62: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` or `repr(object)` instead. For details, see https://docs.neptune.ai/setup/neptune-client_1-0_release_changes\n",
      "  run[\"parameters\"] = params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1751])\n",
      "tensor(0.8601, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8261, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8144, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8121, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8111, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8185, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8104, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8110, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8086, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8108, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8091, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8084, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8074, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8067, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8087, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8066, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8066, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8078, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8065, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8041, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8106, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8024, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8038, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8049, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8050, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8027, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8079, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8019, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8042, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8050, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8051, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8017, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8050, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8038, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8034, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8057, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8039, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8056, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8057, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8050, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8056, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8031, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8068, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8035, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8030, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8042, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8014, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8026, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8038, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8016, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8059, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8019, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8055, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8033, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8036, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8039, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8030, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8023, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8038, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8015, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8007, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7999, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8018, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8025, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8027, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7987, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8020, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7999, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8016, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8009, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7981, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7999, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7996, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8027, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7997, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7993, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7987, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8005, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7996, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7985, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7978, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7954, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7987, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7966, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8015, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8026, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7981, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8002, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8011, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7996, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8026, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7957, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7971, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7964, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7953, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7987, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7993, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7992, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7967, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7981, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8003, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7963, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8005, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7988, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7961, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7997, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7995, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8006, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7978, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7946, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7964, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8012, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7978, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7977, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7971, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7997, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8012, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7992, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7970, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7976, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7988, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7943, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7983, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7955, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7961, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8019, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7980, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8014, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7979, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7941, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7956, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7983, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7993, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7965, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8002, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7979, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7954, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7942, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7945, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7966, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7987, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7950, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8019, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7963, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8018, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8010, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7988, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7993, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8020, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8010, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7962, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7981, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8035, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7965, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7985, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7940, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7971, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7976, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7984, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7966, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7980, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7962, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7973, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7980, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8016, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8005, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7953, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7957, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7996, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8002, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8002, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7972, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7981, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7947, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7979, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7973, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7943, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7983, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7991, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7973, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7971, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7980, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7970, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7963, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7934, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7951, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7965, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7985, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
      "torch.Size([60, 1751])\n"
     ]
    }
   ],
   "source": [
    "for types in types_list:\n",
    "    for j in range(8):\n",
    "\n",
    "        run = neptune.init_run(\n",
    "        project=\"AitBrainLab/Diffusion\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMTMyMzg0My02NzlhLTQ3N2ItYTdmMS0yNTcwNDBmM2QwM2QifQ==\",\n",
    "    )  # your credentials\n",
    "\n",
    "        eeg = EEG_fif(path, base_url, subjects, runs)\n",
    "        raw=eeg.data_to_raw()\n",
    "        raw=raw.filter( 8,35, method='fir', verbose=20)\n",
    "        epochs=eeg.epochs_visu(raw,tmin=0,tmax=7,baseline=(0,2))\n",
    "        X, y = eeg.get_X_y(epochs)\n",
    "        y=y-1\n",
    "\n",
    "        X_train_types,y_train = extrack_online_dataset_types(X,y,types= types)\n",
    "\n",
    "        X_o1 = []\n",
    "        for k in range(X_train_types.shape[0]):\n",
    "            #print(k)\n",
    "            X_o1.append(X_train_types[k][1].tolist())\n",
    "\n",
    "        dataset = torch.tensor(X_o1).float().cuda(0)\n",
    "\n",
    "\n",
    "\n",
    "        betas = make_beta_schedule(schedule='sigmoid', n_timesteps=n_steps, start=1e-6, end=1e-2)\n",
    "        alphas = 1 - betas\n",
    "        alphas_prod = torch.cumprod(alphas, 0)\n",
    "        alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "        alphas_prod_p_sqrt = alphas_prod_p.sqrt()\n",
    "        alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "        one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "        one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "        sqrt_recip_alphas_cumprod = (1 / alphas_prod).sqrt()\n",
    "        sqrt_alphas_cumprod_m1 = (1 - alphas_prod).sqrt() * sqrt_recip_alphas_cumprod\n",
    "        posterior_mean_coef_1 = (betas * torch.sqrt(alphas_prod_p) / (1 - alphas_prod))\n",
    "        posterior_mean_coef_2 = ((1 - alphas_prod_p) * torch.sqrt(alphas) / (1 - alphas_prod))\n",
    "        posterior_variance = betas * (1 - alphas_prod_p) / (1 - alphas_prod)\n",
    "        posterior_log_variance_clipped = torch.log(torch.cat((posterior_variance[1].view(1, 1), posterior_variance[1:].view(-1, 1)), 0)).view(-1)\n",
    "        # Create ADAM optimizer over our model\n",
    "        model = ConditionalModel(n_steps).cuda(0)\n",
    "        if load is True:\n",
    "            model.load_state_dict(torch.load('diffusion_online/[20]_{0}_{1}'.format(j,types)))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "        # Create EMA model\n",
    "        ema = EMA(0.9)\n",
    "        ema.register(model)\n",
    "        batch_size = 1751\n",
    "        params = {\"Subject number\":subjects,\n",
    "                  \"Channel\" : j,\n",
    "                  \"Datasets\":dataset_name,\n",
    "                  \"lr\":0.0001,\n",
    "                  \"n_steps\" : n_steps ,\n",
    "                  \"beta_schedule\" : \"sigmoid\",\n",
    "                  'types' : types,\n",
    "              'low_cut_hz' : 8,\n",
    "              'high_cut_hz': 35\n",
    "\n",
    "                  }\n",
    "\n",
    "        run[\"parameters\"] = params\n",
    "        for t in range(15000):\n",
    "            # X is a torch Variable\n",
    "            permutation = torch.randperm(dataset.size()[0])\n",
    "            loss_old = 500\n",
    "            for z in range(0, dataset.size()[0], batch_size):\n",
    "                # Retrieve current batch\n",
    "                indices = permutation[z:z+batch_size]\n",
    "                batch_x = dataset[indices].cuda(0)\n",
    "                # Compute the loss.\n",
    "                loss = compute_loss(model, batch_x) #compute_loss(model, batch_x)\n",
    "                # Before the backward pass, zero all of the network gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Backward pass: compute gradient of the loss with respect to parameters\n",
    "                loss.backward()\n",
    "                # Perform gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "                # Calling the step function to update the parameters\n",
    "                optimizer.step()\n",
    "                # Update the exponential moving average\n",
    "                ema.update(model)\n",
    "            # Print loss\n",
    "            run[f\"epoch/loss\"].append(loss)\n",
    "            if loss < loss_old:\n",
    "                torch.save(model.state_dict(),'diffusion_online/{0}_{1}_{2}'.format(params['Subject number'],params['Channel'],types))\n",
    "                loss_old = loss\n",
    "                #print(\"save done\")\n",
    "                print(loss)\n",
    "\n",
    "\n",
    "        run.stop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_recon.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
