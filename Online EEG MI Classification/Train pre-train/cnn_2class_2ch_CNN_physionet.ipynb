{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98b0ee-e674-429f-a390-d664ef22eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "from common import train\n",
    "from common import create_dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "wandb.login()\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\" \n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ac9e5-0ffa-4578-89f2-e8bce5c7caf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63f68d-e220-4fbd-9acd-987ca72107d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f0904-0005-4184-93fc-3f0bd2cd815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75684e-46b1-4b7a-9d2b-f77dddfd943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import EEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1af52-b20c-4259-92de-72a9938db85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, out_size):\n",
    "        super().__init__()\n",
    "        #using sequential helps bind multiple operations together\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #padding = (kernel_size - 1) / 2 = 2\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels*2),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(linear_shape  , out_size)\n",
    "        #self.fc = nn.Linear(80064 , 2)\n",
    "        \n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.drop_out(out)\n",
    "        #out = self.layer4(out)\n",
    "        #out = self.drop_out(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)   #can also use .view()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dd475-9fa5-4e81-85b5-ee4104bd56b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798d879-5120-4680-b9fb-94fd92704865",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_all = list(range(1, 110))\n",
    "filter_num =[38,88,89,92,100,104]\n",
    "subjects = [subject for subject in subjects_all if subject not in filter_num]\n",
    "\n",
    "\n",
    "#print(subjects)\n",
    "#[20,31,47,48,49,54,55,59,62]# \n",
    "\n",
    "in_channels  = 2 #C3, C4\n",
    "out_channels = 64  #five is logical because we have freq= 8, 9, 10, 11, 12 that we want to capture\n",
    "out_size     = 2  #left or right\n",
    "kernel_size  = 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c885e-be3b-4b91-a0e5-260b1b696c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PACK\n",
    "for i in range(3):\n",
    "    if i == 0:\n",
    "        n_type = \"physionet_EX\"\n",
    "    if i == 1:\n",
    "        n_type = \"physionet_MI\"\n",
    "    if i == 2:\n",
    "        n_type = \"physionet_ALL\"\n",
    "\n",
    "    if n_type == \"physionet_EX\":\n",
    "        runs = [3,7,11]\n",
    "    if n_type == \"physionet_MI\":\n",
    "        runs = [4,8,12]\n",
    "    if n_type == \"physionet_ALL\":\n",
    "        runs = [3,7,11,4,8,12]\n",
    "    \n",
    "    print(\"############## {} ########\".format(subjects))\n",
    "    path = 'physionet.org/files/eegmmidb/1.0.0'\n",
    "    base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "    eeg = EEG(path, base_url, subjects, runs)\n",
    "    raw=eeg.data_to_raw()\n",
    "    print(\"Raw done\")\n",
    "    \n",
    "    raw=raw.notch_filter([50])\n",
    "    raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "    raw=raw.pick_channels(['C3', 'C4'])\n",
    "    eeg.create_epochs()\n",
    "    X, y = eeg.get_X_y()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "    print('train size',X_train.shape, y_train.shape)\n",
    "    print('Test size',X_test.shape, y_test.shape)\n",
    "    batch_size = X_train.shape[2]\n",
    "    train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "    test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "    num_step =math.ceil(len(train_loader.dataset) / batch_size)\n",
    "\n",
    "    x_train = torch.FloatTensor(X_train)\n",
    "    fake_eeg_data = torch.randn_like(x_train) #(batch_size, channel, length)\n",
    "\n",
    "        #using sequential helps bind multiple operations together\n",
    "    layer1 = nn.Sequential(\n",
    "                #padding = (kernel_size - 1) / 2 = 2\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU()\n",
    "                # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "    layer2 = nn.Sequential(\n",
    "                nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels*2),\n",
    "                nn.ReLU()\n",
    "                # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "    layer3 = nn.Sequential(\n",
    "                nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "\n",
    "    out = layer1(fake_eeg_data)\n",
    "    out = layer2(out)\n",
    "    out = layer3(out)\n",
    "    out = out.reshape(out.size(0), -1)\n",
    "    linear_shape = out.shape[1]\n",
    "    print(linear_shape)\n",
    "    fc = nn.Linear(linear_shape, out_size)\n",
    "    out = fc(out)\n",
    "\n",
    "    wand = wandb.init(\n",
    "\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Motor-Imagery\", \n",
    "          # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=\"CNN_3layer_2class_physionet_{}_newlr\".format(n_type), \n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 0.00001,\n",
    "          \"architecture\": \"CNN\",\n",
    "          \"dataset\": \"S{}\".format(subjects),\n",
    "          \"epochs\": 1000,\n",
    "          \"weightname\":\"CNN_3layer_2class_physionet_{}_newlr\".format(n_type),\n",
    "          \"num_step_per_epoch\" : num_step, \n",
    "\n",
    "          }\n",
    "        )\n",
    "    wandb.login()\n",
    "    config = wand.config\n",
    "    net = ConvNet(in_channels, out_channels, kernel_size, out_size).cuda(0)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "        model = net,\n",
    "        gpu_num = 0,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader,\n",
    "        optimizer = optimizer  ,\n",
    "        criterion = criterion ,\n",
    "        wand = wand\n",
    "             )\n",
    "\n",
    "\n",
    "    wandb.alert(\n",
    "                title='Finish',\n",
    "                text=f'Finishing training',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bd72d-8273-47ee-a2e9-7dba3c7df8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    print(\"############## {} ########\".format(subject))\n",
    "    \n",
    "    path = 'physionet.org/files/eegmmidb/1.0.0'\n",
    "    base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "    n_type = \"physionet_MI\"\n",
    "    \n",
    "    # subjects = [1]\n",
    "    runs = [3, 4, 7, 8, 11, 12]\n",
    "    #runs = [4, 8, 12]\n",
    "    subjects = [subject]#[i for i in range(1,40)]\n",
    "    #subjects = [1]\n",
    "    # runs = [6,10,14]\n",
    "\n",
    "    eeg = EEG(path, base_url, subjects, runs)\n",
    "    raw=eeg.data_to_raw()\n",
    "    print(\"Raw done\")\n",
    "    # apply filter\n",
    "    \n",
    "    raw=raw.notch_filter([50])\n",
    "    raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "    raw=raw.pick_channels(['C3', 'C4'])\n",
    "    eeg.create_epochs()\n",
    "    \n",
    "    print(raw.ch_names)\n",
    "    X, y = eeg.get_X_y()\n",
    "    print(y)\n",
    "    #print(X)\n",
    "    #X2 = X[:, 8:9, :] \n",
    "    #X3= X[:, 12:13, :]\n",
    "    #X = np.concatenate((X2,X3), axis=1)\n",
    "    #y=y-1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "    print('train size',X_train.shape, y_train.shape)\n",
    "    print('Test size',X_test.shape, y_test.shape)\n",
    "    batch_size = X_train.shape[2]\n",
    "    train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "    test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "    num_step =math.ceil(len(train_loader.dataset) / batch_size)\n",
    "    \n",
    "    x_train_fake = torch.FloatTensor(X_train)\n",
    "    fake_eeg_data = torch.randn_like(x_train_fake) #(batch_size, channel, length)\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "            #using sequential helps bind multiple operations together\n",
    "    layer1 = nn.Sequential(\n",
    "                #padding = (kernel_size - 1) / 2 = 2\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU()\n",
    "                # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "    layer2 = nn.Sequential(\n",
    "                nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels*2),\n",
    "                nn.ReLU()\n",
    "                # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "    layer3 = nn.Sequential(\n",
    "                nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    out = layer1(fake_eeg_data)\n",
    "    out = layer2(out)\n",
    "    out = layer3(out)\n",
    "    out = out.reshape(out.size(0), -1)\n",
    "    linear_shape = out.shape[1]\n",
    "    linear_shape\n",
    "    fc = nn.Linear(linear_shape, out_size)\n",
    "    out = fc(out)\n",
    "    out.shape\n",
    "    \n",
    "    wand = wandb.init(\n",
    "\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Motor-Imagery\", \n",
    "          # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=\"CNN_3layer_2class_S{0}_{1}\".format(subject,n_type), \n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 0.000000001,\n",
    "          \"architecture\": \"CNN\",\n",
    "          \"dataset\": \"S{}\".format(subjects[0]),\n",
    "          \"epochs\": 300000,\n",
    "          \"weightname\":\"CNN_3layer_2class_S{0}_{1}\".format(subject,n_type),\n",
    "          \"num_step_per_epoch\" : num_step, \n",
    "\n",
    "          }\n",
    "        )\n",
    "    wandb.login()\n",
    "    config = wand.config\n",
    "    net = ConvNet(in_channels, out_channels, kernel_size, out_size).cuda(0)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "        model = net,\n",
    "        gpu_num = 0,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader,\n",
    "        optimizer = optimizer  ,\n",
    "        criterion = criterion ,\n",
    "        wand = wand\n",
    "             )\n",
    "\n",
    "\n",
    "    wandb.alert(\n",
    "                title='Finish',\n",
    "                text=f'Finishing training',\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8093a220-5344-43b5-a785-58c7d4ae8e06",
   "metadata": {},
   "source": [
    "###Findture\n",
    "641\n",
    "\n",
    "\n",
    "train size (400, 2, 543) (400,)\n",
    "Test size (172, 2, 543) (172,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5f4d6-a65f-4e64-9d64-10b7294795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import EEG_fif\n",
    "from common import create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d20acc-c62f-410c-b7b1-17fe80167b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [20,31,48,50,54,59,62]\n",
    "print(\"subjects number : {} \".format(subjects))\n",
    "\n",
    "#[20,31,47,48,49,54,55,59,62]# list(range(36, 63))\n",
    "\n",
    "in_channels  = 2 #C3, C4\n",
    "out_channels = 64  #five is logical because we have freq= 8, 9, 10, 11, 12 that we want to capture\n",
    "out_size     = 2  #left or right\n",
    "kernel_size  = 5\n",
    "\n",
    "\n",
    "\n",
    "path = ''\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b19c0-15c0-407e-932a-df3c6bfd0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            n_type = \"physionet_EX\"\n",
    "            part_weight = \"CNN_3layer_2class_physionet_physionet_EX_newlr/0.6923_CNN_3layer_2class_physionet_physionet_EX_newlr_0.6923_50.0000\"\n",
    "            runs = [3,5,7,9]\n",
    "            if subject == 31\n",
    "        if i == 1:\n",
    "            n_type = \"physionet_MI\"\n",
    "            part_weight = \"CNN_3layer_2class_physionet_physionet_MI_newlr/0.6904_CNN_3layer_2class_physionet_physionet_MI_newlr_0.6904_53.5018\"\n",
    "            runs = [4,6,8,10]\n",
    "        if i == 2:\n",
    "            n_type = \"physionet_ALL\"\n",
    "            part_weight = \"CNN_3layer_2class_physionet_physionet_ALL_newlr/0.6929_CNN_3layer_2class_physionet_physionet_ALL_newlr_0.6929_50.2349\"\n",
    "            runs = [3,5,7,9,4,6,8,10]\n",
    "\n",
    "            \n",
    "        print(\"############## {} ########\".format(subject))\n",
    "        \n",
    "        eeg = EEG_fif(path, base_url, subjects, runs)\n",
    "        raw=eeg.data_to_raw()\n",
    "        print(\"Raw done\")\n",
    "        raw=raw.notch_filter([50])\n",
    "        raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "        raw.resample(160)\n",
    "        print(\"Filter done\")\n",
    "        raw.pick_channels(['C3', 'C4', 'STIM MARKERS'])\n",
    "        epochs=eeg.epochs_visu(raw,tmin=0,tmax=7,baseline=(0,1))\n",
    "        X, y = eeg.get_X_y(epochs)\n",
    "        X=X[:,:,int(2*160):int(1211-(250*1))]\n",
    "        y=y-1\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "\n",
    "        print('train size',X_train.shape, y_train.shape)\n",
    "        print('Test size',X_test.shape, y_test.shape)\n",
    "        batch_size = X_train.shape[2]\n",
    "        train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "        test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "        num_step =math.ceil(len(train_loader.dataset) / batch_size)\n",
    "\n",
    "        x_train = torch.FloatTensor(X_train)\n",
    "        fake_eeg_data = torch.randn_like(x_train) #(batch_size, channel, length)\n",
    "\n",
    "            #using sequential helps bind multiple operations together\n",
    "        layer1 = nn.Sequential(\n",
    "                    #padding = (kernel_size - 1) / 2 = 2\n",
    "                    nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    nn.ReLU()\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                )\n",
    "        layer2 = nn.Sequential(\n",
    "                    nn.Conv1d(out_channels, out_channels*2, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                    nn.BatchNorm1d(out_channels*2),\n",
    "                    nn.ReLU()\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                )\n",
    "        layer3 = nn.Sequential(\n",
    "                    nn.Conv1d(out_channels*2, out_channels, kernel_size=kernel_size, stride=1, padding=2),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "\n",
    "\n",
    "        out = layer1(fake_eeg_data)\n",
    "        out = layer2(out)\n",
    "        out = layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        linear_shape = out.shape[1]\n",
    "        fc = nn.Linear(linear_shape, out_size)\n",
    "        out = fc(out)\n",
    "\n",
    "        wand = wandb.init(\n",
    "\n",
    "              # Set the project where this run will be logged\n",
    "              project=\"Motor-Imagery\", \n",
    "              # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "              name=\"CNN_3layer_2class_physionet_S{0}_{1}\".format(subject,n_type), \n",
    "              # Track hyperparameters and run metadata\n",
    "              config={\n",
    "              \"learning_rate\": 0.00001,\n",
    "              \"architecture\": \"CNN\",\n",
    "              \"dataset\": \"S{0}\".format(subject),\n",
    "              \"epochs\": 100000,\n",
    "              \"weightname\":\"CNN_3layer_2class_physionet_S{0}_{1}\".format(subject,n_type),\n",
    "              \"num_step_per_epoch\" : num_step, \n",
    "\n",
    "              }\n",
    "            )\n",
    "        wandb.login()\n",
    "        config = wand.config\n",
    "        net = ConvNet(in_channels, out_channels, kernel_size, out_size).cuda(0)\n",
    "        net.load_state_dict(torch.load(part_weight))\n",
    "        for name,param in net.named_parameters():\n",
    "            if param.requires_grad and 'layer1' in name:\n",
    "                param.requires_grad = False\n",
    "            if param.requires_grad and 'layer2' in name:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "            model = net,\n",
    "            gpu_num = 0,\n",
    "            train_loader = train_loader,\n",
    "            test_loader = test_loader,\n",
    "            optimizer = optimizer  ,\n",
    "            criterion = criterion ,\n",
    "            wand = wand\n",
    "                 )\n",
    "\n",
    "\n",
    "        wandb.alert(\n",
    "                    title='Finish',\n",
    "                    text=f'Finishing training',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99404c6-4b17-4a33-b493-cba1b9ef067a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780c8dd-1272-4ac0-874a-dc5787b0059c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd570d28-b38c-4322-9431-7f3a01fbea6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878597af-27e8-4e5f-bdc5-bfcc8fae47e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08ac4b-5067-449a-a5af-99c5861820b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a1912-cc44-457f-9622-624408e5a545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43c9dc-2aeb-4218-b044-ecaaf07b7e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca35f5d-f613-44df-b636-e182e077e656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbaefbc-a919-4bdb-a904-aeb0669b9f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d6e58-f421-4edf-aaae-b1e70781d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
