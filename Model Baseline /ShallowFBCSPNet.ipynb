{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5437aee-2405-48db-9a8e-55b502d84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize, \n",
    "    preprocess, \n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,EEGNetv4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc9d1e3-3e9a-43e5-9db8-5cd28e492c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/braindecode/preprocessing/preprocess.py:52: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    }
   ],
   "source": [
    "subjects = list(range(1,10))\n",
    "\n",
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "#factor_new = 1e-3\n",
    "#init_block_size = 1000\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "preprocessors = [\n",
    "                    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "                    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "                    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "                    ]\n",
    "n_epochs = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fd83b5-89c5-459a-9ff4-e4f7b1e9ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/nutapol1997/EEG-MI/e/EEG-57\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01T.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/002-2014/S01T.mat'.\n",
      "100%|█████████████████████████████████████| 39.8M/39.8M [00:00<00:00, 37.2GB/s]\n",
      "SHA256 hash of downloaded file: cb46cc0530e6e8b4963474cd78b715277def4dc8a9402b4c7a32bb0ebf27c1bc\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01E.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/002-2014/S01E.mat'.\n",
      "100%|█████████████████████████████████████| 23.8M/23.8M [00:00<00:00, 31.5GB/s]\n",
      "SHA256 hash of downloaded file: 0c40f592e721b4624f7ece30cd0c87e765eb09de9e5b9193200da746f165199a\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "20 events found\n",
      "Event IDs: [1 2]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n",
      "512.0\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "20 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 20 events and 2816 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'session_T'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 28\u001B[0m\n\u001B[1;32m     21\u001B[0m windows_dataset \u001B[38;5;241m=\u001B[39m create_windows_from_events(\n\u001B[1;32m     22\u001B[0m     dataset,\n\u001B[1;32m     23\u001B[0m     trial_start_offset_samples\u001B[38;5;241m=\u001B[39mtrial_start_offset_samples,\n\u001B[1;32m     24\u001B[0m     trial_stop_offset_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     25\u001B[0m     preload\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     26\u001B[0m )\n\u001B[1;32m     27\u001B[0m splitted \u001B[38;5;241m=\u001B[39m windows_dataset\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msession\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43msplitted\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msession_T\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     29\u001B[0m valid_set \u001B[38;5;241m=\u001B[39m splitted[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msession_E\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     31\u001B[0m cuda \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()  \u001B[38;5;66;03m# check if GPU is available, if True chooses to use it\u001B[39;00m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'session_T'"
     ]
    }
   ],
   "source": [
    "for subject_id in subjects:\n",
    "    run = neptune.init_run(\n",
    "    project=\"nutapol1997/EEG-MI\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMTMyMzg0My02NzlhLTQ3N2ItYTdmMS0yNTcwNDBmM2QwM2QifQ==\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    dataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids= [subject_id])\n",
    "    preprocess(dataset, preprocessors)\n",
    "    trial_start_offset_seconds = -0.5\n",
    "    # Extract sampling frequency, check that they are same in all datasets\n",
    "    sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "    print(sfreq)\n",
    "    assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "    # Calculate the trial start offset in samples.\n",
    "    trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "    # Create windows using braindecode function for this. It needs parameters to define how\n",
    "    # trials should be used.\n",
    "    windows_dataset = create_windows_from_events(\n",
    "        dataset,\n",
    "        trial_start_offset_samples=trial_start_offset_samples,\n",
    "        trial_stop_offset_samples=0,\n",
    "        preload=True,\n",
    "    )\n",
    "    splitted = windows_dataset.split('session')\n",
    "    train_set = splitted['session_T']\n",
    "    valid_set = splitted['session_E']\n",
    "    \n",
    "    cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "    if cuda:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    seed = 20200220\n",
    "    set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "    n_classes = 4\n",
    "\n",
    "    #n_chans = train_set[0][0].shape[0]\n",
    "    input_window_samples = train_set[0][0].shape[1]\n",
    "    n_channels = windows_dataset[0][0].shape[0]\n",
    "\n",
    "\n",
    "     # For deep4 they should be:\n",
    "    lr = 0.0625 * 0.01\n",
    "    weight_decay = 0\n",
    "\n",
    "    params = {\"Subject number\":subject_id,\n",
    "              \"learning_rate\": lr ,\n",
    "              \"optimizer\": \"AdamW\" ,\n",
    "              \"Network\":\"ShallowFBCSPNet\",\n",
    "              \"Datasets\":\"BNCI2014001\",\n",
    "              \"sfreq\":dataset.datasets[0].raw.info['sfreq'],\n",
    "              \"Class number\":n_classes,\n",
    "              \"Channel number\": train_set[0][0].shape[0] ,\n",
    "              \"wWight decay\":weight_decay}\n",
    "    run[\"parameters\"] = params\n",
    "\n",
    "    # model = ShallowFBCSPNet(\n",
    "    #     n_chans,\n",
    "    #     n_classes,\n",
    "    #     input_window_samples=input_window_samples,\n",
    "    #     final_conv_length='auto',\n",
    "    # )\n",
    "    model = ShallowFBCSPNet(\n",
    "        n_channels,\n",
    "        n_classes,\n",
    "        input_window_samples=input_window_samples,\n",
    "        final_conv_length=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    # model = ShallowFBCSPNet(\n",
    "    #     n_chans,\n",
    "    #     n_classes,\n",
    "    #     input_window_samples=input_window_samples,\n",
    "    #     final_conv_length='auto',\n",
    "    # )\n",
    "    # Send model to GPU\n",
    "    if cuda:\n",
    "        model.cuda(0)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = train_set[0][0].shape[1]#64\n",
    "    \n",
    "\n",
    "    clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "        optimizer__lr=lr,\n",
    "        optimizer__weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "\n",
    "        callbacks=[\n",
    "            \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "        ],\n",
    "        device=device\n",
    "    )\n",
    "    # Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "    # in the dataset.\n",
    "    # wand = wandb.init(\n",
    "    #\n",
    "    #           # Set the project where this run will be logged\n",
    "    #           project=\"Deep4Net_MI\",\n",
    "    #           # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    #           name=\"Deep4Net_S{0}\".format(subject_id),\n",
    "    #         )\n",
    "    # wandb.login()\n",
    "    \n",
    "    \n",
    "    history=clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "    for i in range(len(history.history)):\n",
    "        run[f\"epoch/valid_accuracy\"].append(history.history[i][\"valid_accuracy\"])\n",
    "        run[f\"epoch/train_accuracy\"].append(history.history[i][\"train_accuracy\"])\n",
    "        run[f\"epoch/train_loss\"].append(history.history[i][\"train_loss\"])\n",
    "        run[f\"epoch/valid_loss\"].append(history.history[i][\"valid_loss\"])\n",
    "    label_dict = valid_set.datasets[0].windows.event_id.items()\n",
    "    labels = list(dict(sorted(list(label_dict), key=lambda kv: kv[1])).keys())\n",
    "\n",
    "    X_valid = valid_set.datasets[0].windows.get_data()\n",
    "    y_valid = valid_set.get_metadata().target\n",
    "\n",
    "    X_train = train_set.datasets[0].windows.get_data()\n",
    "    y_train = train_set.get_metadata().target\n",
    "\n",
    "    y_pred = clf.predict(valid_set)\n",
    "    y_probas = clf.predict_proba(valid_set)\n",
    "\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_valid, y_pred)\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "    run.stop()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'session_0': <braindecode.datasets.base.BaseConcatDataset object at 0x7f14a06e8790>}\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
