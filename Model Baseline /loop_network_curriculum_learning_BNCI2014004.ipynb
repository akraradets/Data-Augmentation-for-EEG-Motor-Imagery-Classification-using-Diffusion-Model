{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "\n",
    "\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,HybridNet,EEGInceptionMI,EEGITNet,ATCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    #X2 = X[:, 7:8, :]\n",
    "    #X3= X[:, 11:12, :]\n",
    "    #(288, 22, 1125)\n",
    "    #X = np.concatenate((X2,X3), axis=1)\n",
    "    print(X.shape)\n",
    "\n",
    "    #X = X.reshape(y_shape,X.shape[2],X.shape[1])\n",
    "    return X,np.array(y_).T\n",
    "\n",
    "\n",
    "def extrack_dataset_2class(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "    X_ = np.zeros((int(y_shape/2) ,x_shape[0],x_shape[1])) #for 2 class\n",
    "    y_for_2class =[]\n",
    "    j=0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == 0 or y[i] == 1:\n",
    "            y_for_2class.append(y[i])\n",
    "            X_[j]=X[i]\n",
    "            j +=1\n",
    "    y_for_2class = np.array(y_for_2class).T\n",
    "    X_ = X_.reshape(y_for_2class.shape[0],X_.shape[2],X_.shape[1])\n",
    "    return X_,y_for_2class\n",
    "\n",
    "def extrack_dataset_2class_cut(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    y = np.array(y_).T\n",
    "    X_ = np.zeros((int(y_shape/2) ,x_shape[0],x_shape[1])) #for 2 class\n",
    "    y_for_2class =[]\n",
    "    j=0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == 0 or y[i] == 1:\n",
    "            y_for_2class.append(y[i])\n",
    "            X_[j]=X[i]\n",
    "            j +=1\n",
    "    y_for_2class = np.array(y_for_2class).T\n",
    "    X_ = X_.reshape(y_for_2class.shape[0],X_.shape[2],X_.shape[1])\n",
    "    #100, 1, 576, 22\n",
    "    X_ = X_[:,64:320,:]\n",
    "    print(X_.shape)\n",
    "    return X_,y_for_2class\n",
    "\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True,\n",
    "          lr = None,\n",
    "          subject_id = None\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "\n",
    "            #avg_pedic = torch.mean(outputs, 1, True).float()\n",
    "            #avg_pedic = avg_pedic.reshape(classes.shape[0])\n",
    "            #print(avg_pedic.shape)\n",
    "            #print(classes.shape)\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            #avg_pedic = torch.mean(outputs, 1, True).float()\n",
    "            #avg_pedic = avg_pedic.reshape(classes.shape[0])\n",
    "\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),'BNCI2014002/{}/{:.4f}_{}_{:.4f}_{:.4f}_{}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1],subject_id))\n",
    "                    part_weights = 'BNCI2014002/{}/{:.4f}_{}_{:.4f}_{:.4f}_{}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1],subject_id)\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f , le : %f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1],lr))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "        if epoch+1 == 1:\n",
    "            stop_loss = valid_loss[-1]\n",
    "\n",
    "        if  (epoch+1)//500 == 0 and epoch+1 > 1400 :\n",
    "            if valid_loss[-1] > valid_loss[-500]:\n",
    "                print(\"Stop\")\n",
    "                break\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy,part_weights\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          valid_loader= None,\n",
    "         labels=None,\n",
    "\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    evaluate_accuracy= []\n",
    "    for i, (items, classes) in enumerate(valid_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    evaluate_accuracy.append(correct_scalar / classes.shape[0] )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    left_eva_acc = confusion_mat[0][0]\n",
    "    right_eva_acc = confusion_mat[1][1]\n",
    "    foot_eva_acc = confusion_mat[2][2]\n",
    "    tongue_eva_acc = confusion_mat[3][3]\n",
    "\n",
    "    run[f\"left_eva_acc\"].append(left_eva_acc/72)\n",
    "    run[f\"right_eva_acc\"].append(right_eva_acc/72)\n",
    "    run[f\"foot_eva_acc\"].append(foot_eva_acc/72)\n",
    "    run[f\"tongue_eva_acc\"].append(tongue_eva_acc/72)\n",
    "\n",
    "\n",
    "    run[f\"epoch/eval_ACC\"].append(evaluate_accuracy[-1])\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True).savefig('confusion_matrix/confusion matrices subject_id : {2}_{0}_of_{1}.png'.format(subject_id,params['Datasets'],network))\n",
    "    return y_pred,y_true,correct_scalar,evaluate_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 1125\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 22), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "\n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "\n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints.\n",
    "        self.fc1 = nn.Linear(560, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subjects = 'All'#list(range(1,10))\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 35.  # high cut frequency for filtering\n",
    "resample = 250\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "preprocessors = [\n",
    "                    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "                    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "                    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "                    Preprocessor('resample', sfreq=resample),\n",
    "                    Preprocessor(exponential_moving_standardize,  # Exponential movin standardization\n",
    "                                factor_new=factor_new,\n",
    "                                 init_block_size=init_block_size)\n",
    "                    ]\n",
    "n_epochs = 5000\n",
    "lr = 0.0001\n",
    "\n",
    "weight_decay = 0.5 * 0.0001\n",
    "task_list = ['left', 'right', 'foot', 'tongue']\n",
    "#task_list = ['foot'] ['ATCNet','EEGITNet','ShallowFBCSPNet',]\n",
    "network_list = ['EEGnet','ATCNet','EEGITNet','ShallowFBCSPNet',\"EEGnet\",'Deep4Net']\n",
    "\n",
    "#network_list = ['Deep4Net']\n",
    "#percent_list = [72]\n",
    "percent_list = [18,36,54,72]\n",
    "gpu_num = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subject_id in subjects:\n",
    "    for network in network_list:\n",
    "\n",
    "\n",
    "\n",
    "        for percent in percent_list:\n",
    "            run = neptune.init_run(\n",
    "    project=\"AitBrainLab/BNCI2014002\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMTMyMzg0My02NzlhLTQ3N2ItYTdmMS0yNTcwNDBmM2QwM2QifQ==\",\n",
    ")\n",
    "\n",
    "            #torch.manual_seed(3407)\n",
    "            dataset = MOABBDataset(dataset_name=\"BNCI2014002\", subject_ids= list(range(1,10)))\n",
    "            preprocess(dataset, preprocessors)\n",
    "            trial_start_offset_seconds = -0.5\n",
    "            # Extract sampling frequency, check that they are same in all datasets\n",
    "            sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "            print(sfreq)\n",
    "            assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "            # Calculate the trial start offset in samples.\n",
    "            trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "            # Create windows using braindecode function for this. It needs parameters to define how\n",
    "            # trials should be used.\n",
    "            windows_dataset = create_windows_from_events(\n",
    "                dataset,\n",
    "                trial_start_offset_samples=trial_start_offset_samples,\n",
    "                trial_stop_offset_samples=0,\n",
    "                preload=True,\n",
    "            )\n",
    "            splitted = windows_dataset.split('session')\n",
    "            train_set = splitted['session_T']\n",
    "            valid_set = splitted['session_E']\n",
    "\n",
    "            input_window_samples = train_set[0][0].shape[1]\n",
    "            X_train,y_train = extrack_dataset(train_set)\n",
    "            #X_train = X_train[:, np.newaxis,:,:]\n",
    "\n",
    "            X_valid,y_valid = extrack_dataset(valid_set)\n",
    "            #\n",
    "\n",
    "            X_syntheic = np.load(\"Synthetic_data_ALL/X_subject_All_72_['left', 'right', 'foot', 'tongue'].npy\") #np.load(\"Synthetic_data/X_subject_3_20_[0, 1].npy\")#\n",
    "            y_syntheic = np.load(\"Synthetic_data_ALL/y_subject_All_72_['left', 'right', 'foot', 'tongue'].npy\")#np.load(\"Synthetic_data/y_subject_3_20_[0, 1].npy\")#\n",
    "            #['left', 'right', 'foot', 'tongue']\n",
    "            if len(task_list) == 4:\n",
    "                for task in task_list :\n",
    "                    if task == \"left\":\n",
    "                        ran = np.random.randint(0,72,percent)\n",
    "                        X1 = X_syntheic[ran]\n",
    "                        y1 = y_syntheic[ran]\n",
    "                    if task == \"right\":\n",
    "                        ran = np.random.randint(0,72,percent)\n",
    "                        X2 = X_syntheic[ran]\n",
    "                        y2 = y_syntheic[ran]\n",
    "                    if task == \"foot\":\n",
    "                        ran = np.random.randint(0,72,percent)\n",
    "                        X3 = X_syntheic[ran]\n",
    "                        y3 = y_syntheic[ran]\n",
    "                    if task == \"tongue\":\n",
    "                        ran = np.random.randint(0,72,percent)\n",
    "                        X4 = X_syntheic[ran]\n",
    "                        y4 = y_syntheic[ran]\n",
    "                X_syntheic = np.concatenate((X1,X2,X3,X4),axis=0)\n",
    "                y_syntheic = np.concatenate((y1,y2,y3,y4),axis=0)\n",
    "\n",
    "            if len(task_list)==1:\n",
    "                for task in task_list :\n",
    "                    if task == \"left\":\n",
    "                        X_syntheic = X_syntheic[np.random.randint(0,72,percent)]\n",
    "                        y_syntheic = y_syntheic[np.random.randint(0,72,percent)]\n",
    "                    if task == \"right\":\n",
    "                        X_syntheic = X_syntheic[np.random.randint(72,144,percent)]\n",
    "                        y_syntheic = y_syntheic[np.random.randint(72,144,percent)]\n",
    "                    if task == \"foot\":\n",
    "                        X_syntheic = X_syntheic[np.random.randint(144,216,percent)]\n",
    "                        y_syntheic = y_syntheic[np.random.randint(144,216,percent)]\n",
    "                    if task == \"tongue\":\n",
    "                        X_syntheic = X_syntheic[np.random.randint(216,288,percent)]\n",
    "                        y_syntheic = y_syntheic[np.random.randint(216,288,percent)]\n",
    "\n",
    "            X_train = np.concatenate((X_train,X_syntheic),axis = 0)\n",
    "            y_train = np.concatenate((y_train, y_syntheic),axis = 0)\n",
    "            print(\"Done concatenate\")\n",
    "\n",
    "\n",
    "\n",
    "            if network == \"EEGnet\":\n",
    "                X_train = X_train.reshape(y_train.shape[0],X_train.shape[2],X_train.shape[1])\n",
    "                X_train = X_train[:, np.newaxis,:,:]\n",
    "                print(X_train.shape)\n",
    "                X_valid = X_valid.reshape(y_valid.shape[0],X_valid.shape[2],X_valid.shape[1])\n",
    "                X_valid = X_valid[:, np.newaxis,:,:]\n",
    "                model = EEGNet()\n",
    "                print(X_valid.shape)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_train,y_train, test_size=0.3,stratify=y_train)\n",
    "            label_dict = valid_set.datasets[0].windows.event_id.items()\n",
    "            labels = list(dict(sorted(list(label_dict), key=lambda kv: kv[1])).keys())\n",
    "            print('train size',X_train.shape, y_train.shape)\n",
    "            print('test size',X_test.shape, y_test.shape)\n",
    "\n",
    "            batch_size = X_train.shape[2]\n",
    "\n",
    "            train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "            test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "            valid_loader = create_dataloader(X_valid, y_valid, batch_size=batch_size)\n",
    "            n_classes=4\n",
    "            n_chans = X_train.shape[1]\n",
    "\n",
    "            #network_list = ['ATCNet', 'ShallowFBCSPNet', 'Deep4Net', 'EEGNetv4']\n",
    "            if network == 'ATCNet' :\n",
    "                model = ATCNet(\n",
    "                                n_chans,\n",
    "                                n_classes\n",
    "                                )\n",
    "            if network == \"ShallowFBCSPNet\":\n",
    "                model = ShallowFBCSPNet(\n",
    "                n_chans,\n",
    "                n_classes,\n",
    "                input_window_samples=input_window_samples,\n",
    "                final_conv_length=\"auto\",\n",
    "                )\n",
    "            if network == \"EEGITNet\":\n",
    "                model = EEGITNet(\n",
    "                    n_classes,\n",
    "                    n_chans,\n",
    "                    input_window_samples=input_window_samples,\n",
    "                    )\n",
    "            if network == \"Deep4Net\":\n",
    "                model = Deep4Net(\n",
    "                    n_chans,\n",
    "                    n_classes,\n",
    "                    input_window_samples=input_window_samples,\n",
    "                    final_conv_length='auto',\n",
    "                    n_filters_time=25,\n",
    "                    n_filters_spat=25,\n",
    "                    filter_time_length=10,\n",
    "                    pool_time_length=3,\n",
    "                    pool_time_stride=3,\n",
    "                    n_filters_2=50,\n",
    "                    filter_length_2=10,\n",
    "                    n_filters_3=100,\n",
    "                    filter_length_3=10,\n",
    "                    n_filters_4=200,\n",
    "                    filter_length_4=10,\n",
    "                    first_pool_mode=\"max\",\n",
    "                    later_pool_mode=\"max\",\n",
    "                    drop_prob=0.5,\n",
    "                    #double_time_convs=False,\n",
    "                    split_first_layer=True,\n",
    "                    batch_norm=True,\n",
    "                    batch_norm_alpha=0.1,\n",
    "                    stride_before_pool=False\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "            params = {\"Subject number\":subject_id,\n",
    "                      \"learning_rate\": lr ,\n",
    "                      \"optimizer\": \"AdamW\" ,\n",
    "                      \"Network\": network,\n",
    "                      \"Datasets\":\"BNCI2014001+ALL_diff_{0}.\".format(percent),\n",
    "                      \"sfreq\":dataset.datasets[0].raw.info['sfreq'],\n",
    "                      \"Class number\":n_classes,\n",
    "                      \"Channel number\": train_set[0][0].shape[0],\n",
    "                      \"samples point\" : X_train.shape[2]\n",
    "\n",
    "                      }\n",
    "            run[\"parameters\"] = params\n",
    "            net = model.cuda(gpu_num)\n",
    "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "            criterion = nn.CrossEntropyLoss()#nn.BCELoss()#\n",
    "            train_loss,valid_loss,train_accuracy,valid_accuracy,part_weights =train(\n",
    "                                                                        model = net,\n",
    "                                                                        gpu_num = gpu_num,\n",
    "                                                                        train_loader = train_loader,\n",
    "                                                                        test_loader = test_loader,\n",
    "                                                                        optimizer = optimizer  ,\n",
    "                                                                        criterion = criterion,\n",
    "                                                                        num_epochs=n_epochs,\n",
    "                                                                        save_weights= True,\n",
    "                                                                        lr=lr\n",
    "                                                                             )\n",
    "            model.load_state_dict(torch.load(part_weights))\n",
    "            eval(model = net,\n",
    "                gpu_num = gpu_num,\n",
    "                valid_loader= valid_loader,\n",
    "                 labels=labels,\n",
    "                 )\n",
    "\n",
    "\n",
    "            run.stop()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S01A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S01A.mat'.\n",
      "100%|█████████████████████████████████████| 65.5M/65.5M [00:00<00:00, 72.6GB/s]\n",
      "SHA256 hash of downloaded file: 2d1631084b40b6d1d4059449602d9e7f44cb8cbb5464b7bc204081d4c463e0d4\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S01B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S01B.mat'.\n",
      "100%|█████████████████████████████████████| 65.3M/65.3M [00:00<00:00, 45.1GB/s]\n",
      "SHA256 hash of downloaded file: c1967542288f1081f933c89b0b2b5fd817cc73a130af848951fe15d8a904fc33\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S02A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S02A.mat'.\n",
      "100%|█████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 81.1GB/s]\n",
      "SHA256 hash of downloaded file: 895d404f3b47488fa90c0dc9a1ed8199dedc84d4ffd9ec7eaa5ce596be863090\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S02B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S02B.mat'.\n",
      "100%|█████████████████████████████████████| 64.9M/64.9M [00:00<00:00, 55.9GB/s]\n",
      "SHA256 hash of downloaded file: 0d45430da95c7ba46297c351fb35ca9f95d3b19a433fd051504f3415be450acb\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S03A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S03A.mat'.\n",
      "100%|█████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 63.7GB/s]\n",
      "SHA256 hash of downloaded file: be563a90f06f7c27aa0d25e8f108080212dee9564e4a57a63173d49c2c62a11b\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S03B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S03B.mat'.\n",
      "100%|█████████████████████████████████████| 64.8M/64.8M [00:00<00:00, 28.1GB/s]\n",
      "SHA256 hash of downloaded file: 8b962d8afcf1453e0ea451cdc9ad68d58f64220655c2cbe04c4ce65a0904ccb8\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S04A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S04A.mat'.\n",
      "100%|█████████████████████████████████████| 65.3M/65.3M [00:00<00:00, 49.7GB/s]\n",
      "SHA256 hash of downloaded file: 0d01381d522d7e9f2fb38afd09469a477156e314afd9ef975f6ea91bfcf0ffd0\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S04B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S04B.mat'.\n",
      "100%|█████████████████████████████████████| 65.0M/65.0M [00:00<00:00, 48.6GB/s]\n",
      "SHA256 hash of downloaded file: 8ff5b426ea3568b04d756d91b7686c962f6d58438978b3ba4adb7051198022f7\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S05A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S05A.mat'.\n",
      "100%|█████████████████████████████████████| 65.7M/65.7M [00:00<00:00, 63.4GB/s]\n",
      "SHA256 hash of downloaded file: f7c674cfaabb473822770cef054c1a1ae3f6beb28e4a54c1608fa9c1fb9a9116\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S05B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S05B.mat'.\n",
      "100%|█████████████████████████████████████| 64.6M/64.6M [00:00<00:00, 76.5GB/s]\n",
      "SHA256 hash of downloaded file: 7ed264c798901f852362d6b9478dc24bebfde667ebb7ea5c472ed7ec417d3ca5\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S06A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S06A.mat'.\n",
      "100%|█████████████████████████████████████| 65.4M/65.4M [00:00<00:00, 51.9GB/s]\n",
      "SHA256 hash of downloaded file: e58eb1eecd7d93314f8b53986b7d77df3aa1d664c35d5fdccebffb93243d282d\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S06B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S06B.mat'.\n",
      "100%|█████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 48.1GB/s]\n",
      "SHA256 hash of downloaded file: aa6d573c96af4a4d3912d87ecb26f0c9025c0b44a59c39ffed8ae9194f4ac4d8\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S07A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S07A.mat'.\n",
      "100%|█████████████████████████████████████| 65.3M/65.3M [00:00<00:00, 70.2GB/s]\n",
      "SHA256 hash of downloaded file: 6319916b7cdf7cd2d36f0669bd4a5d08a61dd4a15bae3ffea1fd9db6b38ac0ff\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S07B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S07B.mat'.\n",
      "100%|█████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 39.3GB/s]\n",
      "SHA256 hash of downloaded file: fb74d4bb6de2428b7375c7d028d0184eef984a4f13e1f62eb4aeae2c0b897e92\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S08A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S08A.mat'.\n",
      "100%|█████████████████████████████████████| 65.7M/65.7M [00:00<00:00, 71.3GB/s]\n",
      "SHA256 hash of downloaded file: 0940a95fa9d7577a426b3ce91007032e4479c3c7849a02ff81f96c5c866b33d5\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S08B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S08B.mat'.\n",
      "100%|█████████████████████████████████████| 65.5M/65.5M [00:00<00:00, 81.7GB/s]\n",
      "SHA256 hash of downloaded file: 86786c03b6bd9d3dd1f2864d79a079c4625889ea9ff30561d1d27e9627d2cf18\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S08C.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S08C.mat'.\n",
      "100%|█████████████████████████████████████| 65.5M/65.5M [00:00<00:00, 47.7GB/s]\n",
      "SHA256 hash of downloaded file: a3ab39717ba3a437d31cbdb4a8560e19580fd5e69b93925653942f85e3bf0b11\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S09A.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S09A.mat'.\n",
      "100%|█████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 52.1GB/s]\n",
      "SHA256 hash of downloaded file: a6c3531be0637f79f8fa6a96b3f819cd5f2c8831e10cf9ff493a4c8fc1e5cb52\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S09B.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S09B.mat'.\n",
      "100%|█████████████████████████████████████| 65.3M/65.3M [00:00<00:00, 78.7GB/s]\n",
      "SHA256 hash of downloaded file: c848d2f1d7b709344a258cc7c1ea947978e7e99986720e6adb10d266c1cb10e0\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2015/S09C.mat' to file '/home/nutapolt/mne_data/MNE-bnci-data/database/data-sets/001-2015/S09C.mat'.\n",
      "100%|█████████████████████████████████████| 65.5M/65.5M [00:00<00:00, 47.0GB/s]\n",
      "SHA256 hash of downloaded file: 71a28f806488889445a6cf84f7baecab74d0496fd50293b67dec5772f63e72de\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.0\n"
     ]
    }
   ],
   "source": [
    "dataset = MOABBDataset(dataset_name=\"BNCI2015001\", subject_ids= list(range(1,10)))\n",
    "preprocess(dataset, preprocessors)\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "print(sfreq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'right_hand']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'session_0'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [25], line 16\u001B[0m\n\u001B[1;32m      7\u001B[0m windows_dataset \u001B[38;5;241m=\u001B[39m create_windows_from_events(\n\u001B[1;32m      8\u001B[0m dataset,\n\u001B[1;32m      9\u001B[0m trial_start_offset_samples\u001B[38;5;241m=\u001B[39mtrial_start_offset_samples,\n\u001B[1;32m     10\u001B[0m trial_stop_offset_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     11\u001B[0m preload\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     12\u001B[0m )\n\u001B[1;32m     14\u001B[0m splitted \u001B[38;5;241m=\u001B[39m windows_dataset\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msession\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43msplitted\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msession_0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'session_0'"
     ]
    }
   ],
   "source": [
    "assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the trial start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "dataset,\n",
    "trial_start_offset_samples=trial_start_offset_samples,\n",
    "trial_stop_offset_samples=0,\n",
    "preload=True,\n",
    ")\n",
    "\n",
    "splitted = windows_dataset.split('session')\n",
    "\n",
    "train_set = splitted['session_0']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 3, 1250)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = extrack_dataset(train_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
