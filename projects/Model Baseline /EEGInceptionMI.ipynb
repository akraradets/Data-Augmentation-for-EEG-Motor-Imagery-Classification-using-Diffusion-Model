{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5437aee-2405-48db-9a8e-55b502d84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize, \n",
    "    preprocess, \n",
    "    Preprocessor)\n",
    "from numpy import multiply\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "import neptune.new as neptune\n",
    "\n",
    "\n",
    "\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\"\n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\"\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net ,EEGNetv4,HybridNet,EEGInceptionMI,EEGITNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_dataloader(X, y, batch_size):\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).long()\n",
    "    dataset_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    dl = torch.utils.data.DataLoader(dataset_tensor, batch_size=batch_size, shuffle=True)\n",
    "    return dl\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n",
    "\n",
    "def extrack_dataset(dataset):\n",
    "    for x, y, window_ind in dataset:\n",
    "        x_shape = x.shape\n",
    "        y_shape = len(dataset.get_metadata().target)\n",
    "        break\n",
    "    X = np.zeros((y_shape,x_shape[0],x_shape[1]))\n",
    "    y_=[]\n",
    "    i=0\n",
    "    for x, y, window_ind in dataset:\n",
    "        X[i]=x\n",
    "        y_.append(y)\n",
    "        i+=1\n",
    "    X2 = X[:, 7:8, :]\n",
    "    X3= X[:, 11:12, :]\n",
    "    X = np.concatenate((X2,X3), axis=1)\n",
    "    print(X.shape)\n",
    "    return X,np.array(y_).T\n",
    "\n",
    "def train(model,gpu_num,train_loader,test_loader,\n",
    "          weights_name=False,\n",
    "          optimizer = None,\n",
    "          criterion = None,\n",
    "          num_epochs=500,\n",
    "          vail_loader= None,\n",
    "          save_weights = False,\n",
    "          neptune = True\n",
    "         ):\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = [10,11]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    old_loss = 100\n",
    "    old_acc = 0\n",
    "    valid_loss_vail = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (items, classes) in enumerate(train_loader):\n",
    "            items = Variable(items)\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(items)\n",
    "            loss = criterion(outputs, classes)\n",
    "\n",
    "            iter_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics = {\"train/train_loss\": loss}\n",
    "\n",
    "            #print(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            iterations += 1\n",
    "\n",
    "        train_loss.append(iter_loss/iterations)\n",
    "\n",
    "\n",
    "        train_accuracy.append(( correct.float() / len(train_loader.dataset)))\n",
    "        train_metrics = {\"train/train_loss\": iter_loss/iterations,\n",
    "                       \"train/train_accuracy\": (100 * correct.float() / len(train_loader.dataset))}\n",
    "\n",
    "\n",
    "\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        iterations = 0\n",
    "        model.eval()\n",
    "\n",
    "        for i, (items, classes) in enumerate(test_loader):\n",
    "            classes = classes.type(torch.LongTensor)\n",
    "            items = Variable(items)\n",
    "            classes = Variable(classes)\n",
    "\n",
    "            if cuda.is_available():\n",
    "                items = items.cuda(gpu_num)\n",
    "                classes = classes.cuda(gpu_num)\n",
    "\n",
    "\n",
    "            outputs = model(items)\n",
    "            loss += criterion(outputs, classes).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == classes.data).sum()\n",
    "            #print(\"correct : {}\".format(classes.data))\n",
    "            #print(\"predicted : {}\".format(predicted))\n",
    "            iterations += 1\n",
    "\n",
    "        valid_loss.append(loss/iterations)\n",
    "        correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "        valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "        test_metrics = {\"Test/Test_loss\": loss/iterations,\n",
    "                       \"Test/Test_accuracy\": correct_scalar / len(test_loader.dataset) }\n",
    "        if save_weights is True:\n",
    "            if epoch+1 > 2 and valid_loss[-1] < old_loss and old_acc <= valid_accuracy[-1] :\n",
    "                    newpath = r'./{}'.format(weights_name)\n",
    "                    if not os.path.exists(newpath):\n",
    "                        os.makedirs(newpath)\n",
    "                    torch.save(model.state_dict(),               './{}/{:.4f}_{}_{:.4f}_{:.4f}'.format(weights_name,valid_loss[-1],weights_name,valid_loss[-1],valid_accuracy[-1]))\n",
    "                    old_loss = valid_loss[-1]\n",
    "                    old_acc = valid_accuracy[-1]\n",
    "\n",
    "        print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "                       %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        if early_stopping(train_loss[-1], valid_loss[-1], min_delta=10, tolerance = 20):\n",
    "            print(\"We are at epoch:\", epoch+1)\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "            break\n",
    "        if neptune is True:\n",
    "            run[f\"epoch/valid_accuracy\"].append(valid_accuracy[-1])\n",
    "            run[f\"epoch/train_accuracy\"].append(train_accuracy[-1])\n",
    "            run[f\"epoch/train_loss\"].append(train_loss[-1])\n",
    "            run[f\"epoch/valid_loss\"].append(valid_loss[-1])\n",
    "\n",
    "\n",
    "    return train_loss,valid_loss,train_accuracy,valid_accuracy\n",
    "def eval(model,\n",
    "         gpu_num,\n",
    "          vail_loader= None,\n",
    "         labels=None,\n",
    "         ):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct=0\n",
    "    for i, (items, classes) in enumerate(vail_loader):\n",
    "        classes = classes.type(torch.LongTensor)\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(gpu_num)\n",
    "            classes = classes.cuda(gpu_num)\n",
    "\n",
    "        outputs = model(items)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.clone().cpu().numpy())\n",
    "        y_true.append(classes.data.clone().cpu().numpy())\n",
    "        correct += (predicted == classes.data).sum()\n",
    "    correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct_scalar / len(test_loader.dataset) )\n",
    "\n",
    "    confusion_mat = confusion_matrix(np.array(y_true).T,np.array(y_pred).T )\n",
    "    run[\"confusion matrices subject_id : {0}\".format(subject_id)].upload(plot_confusion_matrix(confusion_mat, class_names=labels,rotate_row_labels=0,rotate_col_labels=90,with_f1_score=True))\n",
    "    return y_pred,y_true,correct_scalar,valid_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc9d1e3-3e9a-43e5-9db8-5cd28e492c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nutapolt/.local/lib/python3.8/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    }
   ],
   "source": [
    "subjects = list(range(1,10))\n",
    "\n",
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(\"pick_types\", eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(\n",
    "        lambda data, factor: np.multiply(data, factor),  # Convert from V to uV\n",
    "        factor=1e6,\n",
    "    ),\n",
    "    Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(\n",
    "        exponential_moving_standardize,  # Exponential moving standardization\n",
    "        factor_new=factor_new,\n",
    "        init_block_size=init_block_size,\n",
    "    ),\n",
    "]\n",
    "n_epochs = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fd83b5-89c5-459a-9ff4-e4f7b1e9ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/AitBrainLab/BaseLine/e/BASELINE-178\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.0\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "(288, 22, 1125)\n",
      "(288, 22, 1125)\n",
      "train size (201, 1125, 22) (201,)\n",
      "test size (87, 1125, 22) (87,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (288x1x22). Calculated output size: (288x1x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 77\u001B[0m\n\u001B[1;32m     75\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(net\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr)\n\u001B[1;32m     76\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\u001B[38;5;66;03m#nn.BCELoss()#\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m train_loss,valid_loss,train_accuracy,valid_accuracy,part_weights \u001B[38;5;241m=\u001B[39m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mgpu_num\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m  \u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43msave_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m                                                                 \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(part_weights))\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28meval\u001B[39m(model \u001B[38;5;241m=\u001B[39m net,\n\u001B[1;32m     90\u001B[0m     gpu_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     91\u001B[0m       vail_loader\u001B[38;5;241m=\u001B[39m valid_loader,\n\u001B[1;32m     92\u001B[0m      labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m     93\u001B[0m      )\n",
      "Cell \u001B[0;32mIn [2], line 132\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, gpu_num, train_loader, test_loader, weights_name, optimizer, criterion, num_epochs, vail_loader, save_weights, neptune, lr)\u001B[0m\n\u001B[1;32m    129\u001B[0m     classes \u001B[38;5;241m=\u001B[39m classes\u001B[38;5;241m.\u001B[39mcuda(gpu_num)\n\u001B[1;32m    131\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 132\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m#avg_pedic = torch.mean(outputs, 1, True).float()\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m#avg_pedic = avg_pedic.reshape(classes.shape[0])\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;66;03m#print(avg_pedic.shape)\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m#print(classes.shape)\u001B[39;00m\n\u001B[1;32m    137\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, classes)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/braindecode/models/eeginception_mi.py:179\u001B[0m, in \u001B[0;36mEEGInceptionMI.forward\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    175\u001B[0m     out \u001B[38;5;241m=\u001B[39m layer(out)\n\u001B[1;32m    177\u001B[0m out \u001B[38;5;241m=\u001B[39m res2 \u001B[38;5;241m+\u001B[39m out\n\u001B[0;32m--> 179\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mave_pooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflat(out)\n\u001B[1;32m    181\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622\u001B[0m, in \u001B[0;36mAvgPool2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 622\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mavg_pool2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mceil_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount_include_pad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivisor_override\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given input size: (288x1x22). Calculated output size: (288x1x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "\n",
    "for subject_id in subjects:\n",
    "    run = neptune.init_run(\n",
    "    project=\"AitBrainLab/BaseLine\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMTMyMzg0My02NzlhLTQ3N2ItYTdmMS0yNTcwNDBmM2QwM2QifQ==\",\n",
    ")\n",
    "\n",
    "\n",
    "    dataset_name=\"BNCI2014001\"\n",
    "    dataset = MOABBDataset(dataset_name=dataset_name, subject_ids= [1])\n",
    "    preprocess(dataset, preprocessors)\n",
    "    trial_start_offset_seconds = -0.5\n",
    "    # Extract sampling frequency, check that they are same in all datasets\n",
    "    sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "    print(sfreq)\n",
    "    assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "    # Calculate the trial start offset in samples.\n",
    "    trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "    # Create windows using braindecode function for this. It needs parameters to define how\n",
    "    # trials should be used.\n",
    "    windows_dataset = create_windows_from_events(\n",
    "        dataset,\n",
    "        trial_start_offset_samples=trial_start_offset_samples,\n",
    "        trial_stop_offset_samples=0,\n",
    "        preload=True,\n",
    "    )\n",
    "    splitted = windows_dataset.split('session')\n",
    "    train_set = splitted['session_T']\n",
    "    valid_set = splitted['session_E']\n",
    "\n",
    "    input_window_samples = train_set[0][0].shape[1]\n",
    "    X_train,y_train = extrack_dataset(train_set)\n",
    "    X_valid,y_valid = extrack_dataset(valid_set)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train,y_train, test_size=0.3,stratify=y_train)\n",
    "    label_dict = valid_set.datasets[0].windows.event_id.items()\n",
    "    labels = list(dict(sorted(list(label_dict), key=lambda kv: kv[1])).keys())\n",
    "    print('train size',X_train.shape, y_train.shape)\n",
    "    print('test size',X_test.shape, y_test.shape)\n",
    "    batch_size = X_train.shape[2]\n",
    "\n",
    "    train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "    test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "    valid_loader = create_dataloader(X_valid, y_valid, batch_size=batch_size)\n",
    "    n_classes=4\n",
    "    n_chans = X_train.shape[1]\n",
    "    model = EEGInceptionMI(\n",
    "                    n_chans,\n",
    "                    n_classes,\n",
    "\n",
    "                    )\n",
    "    seed = 20200220\n",
    "    set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "    n_classes = 4\n",
    "\n",
    "    input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "\n",
    "\n",
    "    lr = 1 * 0.0001\n",
    "\n",
    "\n",
    "    params = {\"Subject number\":subject_id,\n",
    "              \"learning_rate\": lr ,\n",
    "              \"optimizer\": \"AdamW\" ,\n",
    "              \"Network\":\"EEGInceptionMI\",\n",
    "              \"Datasets\":dataset_name,\n",
    "              \"sfreq\":dataset.datasets[0].raw.info['sfreq'],\n",
    "              \"Class number\":n_classes,\n",
    "              \"Channel number\": train_set[0][0].shape[0],\n",
    "              'low_cut_hz' : low_cut_hz,\n",
    "              'high_cut_hz': high_cut_hz\n",
    "              }\n",
    "    run[\"parameters\"] = params\n",
    "    net = model.cuda(0)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "                                                                model = net,\n",
    "                                                                gpu_num = 0,\n",
    "                                                                train_loader = train_loader,\n",
    "                                                                test_loader = test_loader,\n",
    "                                                                optimizer = optimizer  ,\n",
    "                                                                criterion = criterion,\n",
    "                                                                num_epochs=n_epochs\n",
    "                                                                     )\n",
    "    eval(model = net,\n",
    "        gpu_num = 0,\n",
    "          vail_loader= valid_loader,\n",
    "         labels=labels,\n",
    "         )\n",
    "\n",
    "\n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    run.stop()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
